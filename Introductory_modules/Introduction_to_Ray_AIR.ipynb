{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Ray AI Runtime (AIR)\n",
    "\n",
    "<img src=\"../_static/assets/Generic/ray_logo.png\" width=\"20%\" loading=\"lazy\">\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "### Is it right for you?\n",
    "\n",
    "This notebook is an example-based introduction to the Ray AI Runtime (AIR).\n",
    "\n",
    "You will go through an end-to-end example that covers data loading, training, hyper-parameter tuning, predicting and serving. Along the way you will learn about Ray AIR's specialized libraries that collectively form a unified API for scalable ML applications.\n",
    "\n",
    "It is right for you if:\n",
    "\n",
    "* have basic familiarity with Ray project\n",
    "* you want to learn about Ray AIR: the unified API for scalable ML applications\n",
    "* you have an existing ML application or workload and you look for tools that will let you scale it easily.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "For this notebook you should have:\n",
    "\n",
    "* practical Python and machine learning experience\n",
    "\n",
    "You have completed:\n",
    "* [Overview of Ray](https://github.com/ray-project/ray-educational-materials/blob/main/Introductory_modules/Overview_of_Ray.ipynb)\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "Upon completion of this notebook, you will know about:\n",
    "\n",
    "* high-level ML libraries that compose Ray AIR: Data, Train, Tune, Serve, and RLlib\n",
    "* how to use Ray AIR as a unified toolkit to write an end-to-end ML application in Python as well as scale individual jobs\n",
    "* problems and challenges that Ray AIR attempt to solve\n",
    "\n",
    "### What will you do?\n",
    "\n",
    "You will run and analyze an end-to-end example that covers all Ray AIR libraries. Via hands-on exercises you will practice the key concepts from each stage of the example ML workflow:\n",
    "\n",
    "|ML workflow stage|Ray AIR key concept|\n",
    "|:--|:--|\n",
    "|data loading and preprocessing|`Preprocessor` to load and transform data|\n",
    "|model training|`Trainer` for supported ML frameworks (Keras, Pytorch and more)|\n",
    "|hyper-parameter tuning|`Tuner` for hyperparameter search|\n",
    "|batch prediction at scale|`BatchPredictor` to load model from best checkpoint for batch inference|\n",
    "|model serving|`PredictorDeployment` for online inference|\n",
    "\n",
    "You will also scale reinforcement learning (RL) application with RLlib and practice key concepts relevant in the RL domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Overview of Ray AI Runtime (AIR)\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-air/getting-started.html\" target=\"_blank\">Ray AI Runtime (AIR)</a></strong> is an open-source, Python, domain specific library that equips ML engineers, data scientists, and researchers with a scalable and unified toolkit for ML applications.\n",
    "</div>\n",
    "\n",
    "Ray AIR is built on top of Ray core. It caters for distributed data processing, model training, tuning, model serving, and reinforcement learning, all in Python. To that end it enables both individual workloads and end-to-end use cases to be implemented in the single unified library.\n",
    "\n",
    "### Machine learning workflow with Ray AIR\n",
    "\n",
    "Each of the five native libraries that Ray AIR wraps is focused on a specific stage of the ML workflow. Because this abstraction layer is built on top of Ray Core, it is distributed and scalable. Ray AIR brings together an ever-growing ecosystem of integrations with your favorite machine learning frameworks.\n",
    "\n",
    "|<img src=\"../_static/assets/Introduction_to_Ray_AIR/e2e_air.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Ray AIR enables end-to-end ML development and provides multiple options to integrate with other tools and libraries form the MLOps ecosystem.|\n",
    "\n",
    "1. [Ray Data](https://docs.ray.io/en/latest/data/dataset.html): scalable, framework-agnostic loading and transforming raw data\n",
    "1. [Ray Train](https://docs.ray.io/en/latest/train/train.html): distributed multi-node and multi-core model training with fault tolerance that integrates with your favorite training libraries\n",
    "1. [Ray Tune](https://docs.ray.io/en/latest/tune/index.html): scales experiment execution and hyper-parameter tuning to optimize model performance\n",
    "1. [Ray Serve](https://docs.ray.io/en/latest/serve/index.html): deploys your model for online or batch inference\n",
    "1. [Ray RLlib](https://docs.ray.io/en/latest/rllib/index.html): distributed reinforcement learning workloads that integrate with the other Ray AIR libraries above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: End to end ML workflow with Ray AI Runtime\n",
    "\n",
    "### Overview\n",
    "\n",
    "Predicting Big Tips w/ NYC Taxi Data\n",
    "example application: predicting big tips on yellow taxi cabs in New York City.\n",
    "\n",
    "To illustrate Ray AIR's capabilities, you will implement an end-to-end example, building a simple machine learning pipeline using Ray Data, Train, Tune, and Serve. Each part will introduce key concepts, integrations, and typical workloads for the AIR library before demonstrating its functionality with a code example.\n",
    "\n",
    "#### Data\n",
    "\n",
    "#### Model\n",
    "\n",
    "#### Notes\n",
    "Suppose we want to build an application for taxi drivers in NYC that predicts if a given ride will result in a large tip (<20%). This has the potential to influence drivers' decisions when accepting jobs to maximize their margin, and conversations around [information accessbility for gig workers](https://www.nytimes.com/2022/10/11/technology/gig-workers-drivers-para-app.html) are making waves in the news. For this project, let's use the [New York City Taxi & Limousine Commission's Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) to build a binary classification model. Starting off, let's take the yellow cab data from June 2021 which contains over 2 million samples with features including `passenger_count`, `trip_distance` (in miles), `fare_amount` (including tax, tip, fees, etc.), `trip_duration` (in seconds), `hour` (hour that trip started), `day_of_week`, and our target `is_big_tip` (whether the tip amount was greater than 20%).\n",
    "\n",
    "Our workflow will consist of loading data, setting up a preprocessor, training the model with XGBoost, tuning hyperparameters, performing batch inference, and finally serving our online application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Data\n",
    "\n",
    "\n",
    "![Data Highlight](../_static/assets/Introduction_to_Ray_AIR/data_highlight.png)\n",
    "\n",
    "First up, we want to load in the taxi dataset and transform its raw input into features that will be given to our machine learning model.\n",
    "\n",
    "[Ray Datasets](https://docs.ray.io/en/latest/data/user-guide.html) are the standard way to load and pass data in Ray libraries and applications. This common basis for data handling allows users to leverage different libraries from the Ray ecosystem in whatever way serves their needs without being tethered to a particular framework.\n",
    "\n",
    "The benefits of using the core `Dataset` abstractions for loading, transforming, and passing references to data in a Ray cluster include:\n",
    "\n",
    "- **Flexibility**: Compatible with a variety of file formats, data sources, and distributed frameworks, Datasets work seamlessly with library integrations like Dask on Ray and can be passed between Ray tasks and actors without copying data.\n",
    "- **Performance for ML Workloads**: Datasets offers important features like accelerator support, pipelining, and global random shuffles that accelerate ML training and inference workloads along with basic distributed data transformations such as map, filter, sort, groupby, and repartition.\n",
    "- **Persistent Preprocessor**: The `Preprocessor` primitive explicitly captures and stores the transformations applied to convert inputs into features and is applied at both training and serving to keep the processing consistent across the pipeline.\n",
    "- **Built on Ray Core**: inherits scalability to hundreds of nodes, efficient memory usage due to memory across processes on the same node, and object spilling and recovery to handle failures. Because Datasets are just lists of object references, they can be passed between tasks and actors without needing to make a copy of the data, which is crucial for making data-intensive applications and libraries scalable.\n",
    "\n",
    "In *Figure 3* below, you can see the a general pattern for creating a `Dataset`, configuring a `Preprocessor`, and passing these into the `Trainer` for consistent data handling throughout the pipeline.\n",
    "\n",
    "![Ray Data Code Snippet](../_static/assets/Introduction_to_Ray_AIR/data_code.png)\n",
    "\n",
    "*Figure 3*\n",
    "\n",
    "Let's take this generic structure and see how it plays out with our tip prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(a). Import Relevant Packages + Starting Ray\n",
    "To start, we'll import Ray (check out our [installation instructions](https://docs.ray.io/en/latest/ray-overview/installation.html)) and start a Ray cluster on our machine that can utilize all the cores available to you as workers. We use `ray.is_initialized` to ensure that we only have one Ray cluster active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(b). Create Ray Dataset\n",
    "Here, we read in the data from an S3 `.parquet` datasource, a column-major format designed to support fast data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ray.data.read_parquet(\"s3://anyscale-training-data/intro-to-ray-air/nyc_taxi_2021.parquet\")\n",
    "\n",
    "# split data into training and validation subsets\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# split datasets into blocks for parallel preprocessing\n",
    "train_dataset.repartition(100)\n",
    "valid_dataset.repartition(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Exercise**\n",
    "\n",
    "There exist many [`Dataset` API elements](https://docs.ray.io/en/latest/data/api/dataset.html#) available for common transformations and operations. Using the above as a reference:\n",
    "1. Inspect the schema from the underlying Parquet metadata.\n",
    "2. Count how many rows are in the training and validation datasets.\n",
    "3. Inspect the first five samples of either dataset.\n",
    "4. What is the average `fare_amount` grouped by `passenger_count`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "\n",
    "print(f\"Schema of Training Dataset: \\n {train_dataset.schema()}\") # <1>\n",
    "\n",
    "print(f\"Number of Samples in Training Dataset: \\n {train_dataset.count()}\") # <2>\n",
    "print(f\"Number of Samples in Validation Dataset: \\n {valid_dataset.count()}\") # <2>\n",
    "\n",
    "train_dataset.show(5) # <3>\n",
    "\n",
    "train_dataset.groupby('passenger_count').mean('fare_amount').show() # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(c). Preprocessing\n",
    "To transform our raw data -> features, we'll define a `Preprocessor`. What's nice about a Ray AIR `Preprocessor` is that it is automatically incorporated...\n",
    "\n",
    "- **During Training**: `Preprocessor` is passed into a `Trainer` to `fit` and `transform` input `Dataset`s.\n",
    "- **During Tuning**: each `Trial` will instantiate its own copy of the `Preprocessor` and the fitting and transformation logic will occur once per `Trial`\n",
    "- **During Checkpointing**: the `Preprocessor` is saved in the `Checkpoint` if was passed into the `Trainer`\n",
    "- **During Predicting**: if the `Checkpoint` contains a `Preprocessor`, then it will be used to call `transform_batch` on input batches prior to performing inference\n",
    "\n",
    "In the code below, we define a `MinMaxScaler` preprocessor that will scale the `trip_distance` and `trip_duration` columns by their range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import MinMaxScaler\n",
    "\n",
    "# create a preprocessor to scale some columns\n",
    "preprocessor = MinMaxScaler(columns=[\"trip_distance\", \"trip_duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Exercise**\n",
    "\n",
    "Ray AIR provides several [preprocessors out of the box](https://docs.ray.io/en/latest/ray-air/preprocessors.html#) as well as support for implementing custom preprocessors. \n",
    "\n",
    "For this exercise, visualize the distribution for each of the features in our dataset, read through the \"Which preprocessor should you use?\" section of the linked user guide above, and determine whether `MinMaxScaler` applied to `trip_distance` and `trip_duration` is sufficient.\n",
    "\n",
    "Later on, you can compare model performance between the given preprocessor and your custom configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "\n",
    "from ray.data.preprocessors import *\n",
    "\n",
    "pd_df = train_dataset.to_pandas(limit=1893433)\n",
    "pd_df.hist(\"trip_distance\")\n",
    "pd_df.hist(\"trip_duration\")\n",
    "\n",
    "sample_preprocessor = PowerTransformer(columns=[\"trip_distance\", \"trip_duration\"], power=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the positively-skewed distributions for `trip_distance` and `trip_duration`. For these numerical features, you can choose an appropriate AIR `Preprocessor` depending on your data's properties:\n",
    "\n",
    "- `PowerTransformer`: your data isn't normal, but you need it to be\n",
    "- `Normalizer`: you need unit norm rows\n",
    "- `MinMaxScaler`: you aren't sure what your data looks like\n",
    "\n",
    "Feature scaling can offer a performance boost during training, and testing choice of `Preprocessor` is worth investigating when you have few features which are not already unit normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts in This Section**\n",
    "\n",
    "`Dataset`: The standard way to load and exchange data in Ray AIR. In AIR, Datasets are used extensively for data loading, preprocessing, and batch inference.\n",
    "\n",
    "`Preprocessors`: Preprocessors are primitives that can be used to transform input data into features. Preprocessors operate on Datasets, which makes them scalable and compatible with a variety of datasources and dataframe libraries. A Preprocessor is fitted during Training, and applied at runtime in both Training and Serving on data batches in the same way. AIR comes with a collection of built-in preprocessors, and you can also define your own with simple templates which you can read more about in our [User Guide](https://docs.ray.io/en/latest/ray-air/preprocessors.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Train\n",
    "***\n",
    "\n",
    "![Train Highlight](../_static/assets/Introduction_to_Ray_AIR/train_highlight.png)\n",
    "\n",
    "Following data preprocessing, we can move forward with defining our model for binary classification of big tip rides.\n",
    "\n",
    "[Ray Train](https://docs.ray.io/en/latest/ray-air/trainer.html) is a library for distributed training on Ray. It offers key tools for different parts of the training workflow, from feature processing, to scalable training, to integrations with ML tracking tools, to export mechanisms for models.\n",
    "\n",
    "Ray AIR `Trainer`s enable users to distribute training with popular machine learning frameworks like PyTorch, Tensorflow, XGBoost, HuggingFace Transformers, Scikit-Learn, and more. Train supports features like callbacks for early stopping, checkpointing, and integration with Tensorboard, Weights/Biases, and MLflow for observability.\n",
    "\n",
    "ML pracitioners tend to run into a few common problems with training models that prompt them to consider distributed solutions:\n",
    "\n",
    "1. training time is too long to be practical\n",
    "2. the data is too large to fit on one machine\n",
    "3. the model itself is too large to fit on a single machine\n",
    "\n",
    "Ray Train tackles the first problem by running distributed multi-node training with fault tolerance, leveraging Ray Data to scale preprocessing and distributed data ingestion. It is also composable with Ray Tune for scaling hyperparameter tuning and outputs the trained model in the form of a `Checkpoint` for batch inference.\n",
    "\n",
    "In *Figure 4* below, you see that training comes in two major parts: defining the `Trainer` object and then fitting it to the training dataset. In this code snippet, we use a `TorchTrainer`, however, this may be swapped out with any [integrations](https://docs.ray.io/en/latest/ray-air/package-ref.html#trainer-and-predictor-integrations).\n",
    "\n",
    "![Ray Train Code Snippet](../_static/assets/Introduction_to_Ray_AIR/train_code.png)\n",
    "\n",
    "*Figure 4*\n",
    "\n",
    "Let's put these concepts in practice by applying it to our taxi problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(a). Define AIR `Trainer`\n",
    "\n",
    "There are three broad categories of Trainers that AIR offers:\n",
    "\n",
    "- Deep Learning Trainers (Pytorch, Tensorflow, Horovod)\n",
    "- Tree-based Trainers (XGBoost, LightGBM)\n",
    "- Other ML frameworks (HuggingFace, Scikit-Learn, RLlib)\n",
    "\n",
    "In the example below, we will use an `XGBoostTrainer`to perform binary classification on these NYC Taxi rides. To construct a `Trainer`, you provide:\n",
    "\n",
    "- a `ScalingConfig` which specifies how many parallel training workers and what type of resources (CPUs/GPUs) to use per worker during training.\n",
    "- a collection of datasets and a preprocessor for the provided datasets which configures preprocessing and the datasets to ingest from\n",
    "\n",
    "Optionally, you can choose to add `resume_from_checkpoint` which is a checkpoint path to resume from, should your training run be interrupted.\n",
    "\n",
    "Below, we'll set up an `XGBoostTrainer` for our classification task. [XGBoost](https://xgboost.readthedocs.io/en/stable/) is a gradient boosted decision trees library. We'll then supply our `Preprocessor` from the previous step as well as training and validation datasets to ingest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "\n",
    "    label_column=\"is_big_tip\",\n",
    "    num_boost_round=100,\n",
    "\n",
    "    scaling_config=ScalingConfig(\n",
    "        # number of workers to use\n",
    "        num_workers=8,\n",
    "        # whether to use GPU acceleration\n",
    "        use_gpu=False),\n",
    "\n",
    "    # XGBoost specific params\n",
    "    params={\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "        \"tree_method\": \"approx\"\n",
    "    },\n",
    "\n",
    "    # feed in our datasets and preprocessor\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    "    preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(b). Fit the Trainer\n",
    "\n",
    "To invoke training, call `.fit()`. Trainer objects produce a `Result` object which gives you access to metrics, checkpoints, and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Exercise**\n",
    "\n",
    "You can check out the training results from the `Result` object with the following calls:\n",
    "\n",
    "```python\n",
    "# returns last saved checkpoint\n",
    "result.checkpoint\n",
    "\n",
    "# returns the `n` best saved checkpoints as configured in `RunConfig.CheckpointConfig`\n",
    "result.best_checkpoints\n",
    "\n",
    "# returns the final metrics as reported\n",
    "result.metrics\n",
    "\n",
    "# returns the contain an Exception if training failed\n",
    "result.error\n",
    "```\n",
    "\n",
    "Inspect your training result below. What is the reported accuracy for the training and validation runs? \n",
    "\n",
    "Note: `error` is the binary classification error rate in this case calculated as `#(wrong cases)/#(all cases)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "\n",
    "print(f\"Result Metrics: \\n {result.metrics} \\n\")\n",
    "print(f\"Training Accuracy: \\n {1 - result.metrics['train-error']} \\n\")\n",
    "print(f\"Validation Accuracy: \\n {1 - result.metrics['valid-error']} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts in This Section**\n",
    "\n",
    "`Trainer`: Trainers are wrapper classes around third-party training frameworks such as XGBoost, Pytorch, and Tensorflow. They are built to help integrate with core Ray Actors (for distribution), Ray Tune, and Ray Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Tune\n",
    "***\n",
    "\n",
    "![Tune Highlight](../_static/assets/Introduction_to_Ray_AIR/tune_highlight.png)\n",
    "\n",
    "Now that we have a baseline XGBoost model trained, we find the classification accuracy lacking. Among several methods to improve performance (collecting more data, feature engineering, choosing a different algorithm, transfer learning, etc.), **hyperparameter tuning** involves inserting the training loop into an optimization method to find the optimal set of hyperparameters and can be a powerful way to run experiements to achieve good results.\n",
    "\n",
    "*Hyperparameters*, unlike model parameters which are learned by the model as it trains, are parameters that *you, the human* set. These hyperparameters remain static through a `trial` or experiement and influence the final outcome of training. For example, some common variables to adjust could include:\n",
    "\n",
    "- `max_depth` in decision tree models\n",
    "- `drop_out` rate in neural networks\n",
    "- `discount_factor` in Q-learning\n",
    "- `num_iterations` in logistic regression\n",
    "- `n_grams` size of \"n\" in natural language processing\n",
    "\n",
    "Setting up and executing hyperparameter optimization (HPO) in itself can be expensive in terms of compute resources and runtime, but there are several intricacies in making the process work *well*, including:\n",
    "\n",
    "- **Vast Search Space**: your model could have anywhere between a handful to several dozen available hyperparameters, each with different data types and ranges. Some parameters might be correlated. Sampling good candidates from high-dimensional spaces is difficult.\n",
    "- **Search Algorithms**: choosing hyperparameters at random can work surprisingly well, but in general, you need to test complex search algirhtms to achieve the best result.\n",
    "- **Long Runtime**: even if you distribute tuning, training complex models in themselves can take a long time to complete per run, so it's best to have an efficiency at every stage in the pipeline.\n",
    "- **Resource Allocation**: you must have enough compute resources available to during each trial as to not slow down search because of scheduling mismatches.\n",
    "- **User Experience**: HPO is complicated, and visibility and tooling for developers like stopping bad runs early, saving intermediate results, restarting from checkpoints, or pausing and resume runs makes the process easier on the human.\n",
    "\n",
    "Ray Tune is a distributed HPO library that addresses all of these topics above to provide a simplified interface for running trials and integrates with popular frameworks such as HyperOpt, Optuna, and many more.\n",
    "\n",
    "In *Figure 5*, you'll find the general pattern for using AIR `Tuner`s which involves taking in a trainable, defining a search space, establishing a search algorithm, scheduling trials, and analyzing results. We'll go over the relevant components in the following section.\n",
    "\n",
    "![Ray Tune Code Snippet](../_static/assets/Introduction_to_Ray_AIR/tune_code.png)\n",
    "\n",
    "*Figure 5*\n",
    "\n",
    "Let's see how to interact with Ray Tune to make some improvements to our big tip classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(a). Use AIR `Tuner` for Hyperparameter Search\n",
    "\n",
    "To set up an AIR `Tuner`, we must specify:\n",
    "\n",
    "- `search space`: a set of hyperparameters you wish to tune\n",
    "- `search_algorithm`: to optimize parameter search\n",
    "- `scheduler`: (optional) to stop searches early and speed up experiments\n",
    "\n",
    "We pass the `search space`, `search algorithm`, `scheduler`, and `Trainer` to the `Tuner`, which runs the workload by evaluating multiple hyperparameters in parallel. Afterwards, `Tuner` returns its results in a `ResultGrid` for you to analyze.\n",
    "\n",
    "Below, we'll define a search space with a few hyperparameters to tune. \n",
    "\n",
    "- `eta` is the learning rate\n",
    "- `max_depth` specifies how deep each tree is with a default of 6. A higher value leads to a more complex model. Using `tune.randint(1, 9)`, it will sample an integer uniformly between 1 and 9, inclusive.\n",
    "- `min_child_weight` defines the minimum sum of weights of all observations in a child, used to control overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.tuner import Tuner, TuneConfig\n",
    "\n",
    "param_space = {\"params\":\n",
    "    {\n",
    "    \"eta\": tune.uniform(0.2, 0.4),\n",
    "    \"max_depth\": tune.randint(1, 9),\n",
    "    \"min_child_weight\": tune.uniform(0.8, 1.0)\n",
    "    }\n",
    "}\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space=param_space,\n",
    "    tune_config=TuneConfig(num_samples=10, metric=\"train-logloss\", mode=\"min\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(b). Execute Hyperparameter Search & Analyze Results\n",
    "\n",
    "Now, we can execute tuning on our 10 trials. After tuning, we can query the `ResultGrid` object to see metrics, results, and checkpoints of each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grid = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Exercise**\n",
    "\n",
    "You can probe the `ResultGrid` for metrics using these calls:\n",
    "\n",
    "```python\n",
    "\n",
    "# checks if there have been errors\n",
    "result_grid.errors\n",
    "\n",
    "# gets the best result\n",
    "best_result = result_grid.get_best_result()\n",
    "\n",
    "# gets the best checkpoint\n",
    "best_checkpoint = best_result.checkpoint\n",
    "\n",
    "# gets the best metrics\n",
    "best_metrics = best_result.metrics\n",
    "\n",
    "```\n",
    "\n",
    "Inspect your tunings results, what is the best result from these experiments? Are they better than the baseline model in the training step in the previous section?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "\n",
    "best_result = result_grid.get_best_result()\n",
    "\n",
    "print(f\"Best Result: \\n {best_result} \\n\")\n",
    "print(f\"Training Accuracy: \\n {1 - best_result.metrics['train-error']} \\n\")\n",
    "print(f\"Validation Accuracy: \\n {1 - best_result.metrics['valid-error']} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Exercise**\n",
    "\n",
    "`Tuner` allows you to specify an optimization algorithm via the `TuneConfig` by setting the following flags:\n",
    "\n",
    "- `search_alg` which provides an optimizer for selecting the optimal hyperparameters\n",
    "- `scheduler` which provides a scheduling/resource allocation algorithm for accelerating the search process\n",
    "\n",
    "Read more about [schedulers](https://docs.ray.io/en/latest/tune/key-concepts.html#schedulers-ref) and [search algorithms](https://docs.ray.io/en/latest/tune/key-concepts.html#search-alg-ref) in Ray AIR and implement them on this example to see a difference in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MY CODE HERE ###\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.tuner import Tuner, TuneConfig\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "from ray import air\n",
    "\n",
    "algo = BayesOptSearch(random_search_steps=4)\n",
    "\n",
    "param_space = {\"params\":\n",
    "    {\n",
    "    \"eta\": tune.uniform(0.2, 0.4),\n",
    "    \"max_depth\": tune.randint(1, 9),\n",
    "    \"min_child_weight\": tune.uniform(0.8, 1.0)\n",
    "    }\n",
    "}\n",
    "\n",
    "sample_tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space=param_space,\n",
    "    tune_config=TuneConfig(\n",
    "        num_samples=10, \n",
    "        metric=\"train-logloss\", \n",
    "        mode=\"min\", \n",
    "        search_alg=algo\n",
    "    ),\n",
    ")\n",
    "\n",
    "sample_result_grid = sample_tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the hyperparameters of your training process, you can use a search algorithm which suggests hyperparameter configurations. In this example, you run Tune with simple Bayesian optimization through the `bayesian-optimization` package (make sure to first run `pip install bayesian-optimization`). \n",
    "\n",
    "Here, the modified code:\n",
    "\n",
    "- defines an algorithm using `BayesOptSearch`\n",
    "- passes in the `search_alg` argument to `tune.TuneConfig`, which is taken in by Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts in This Section**\n",
    "\n",
    "`Tuner`: provides an interface that works with AIR `Trainer`s to perform distributed hyperparameter tuning. You define a set of hyperparameters you wish to tune in a search space, specify a search algorithm, and the `Tuner` returns its results in a `ResultGrid` that contains metrics, results, and checkpoints for each `trial`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray AIR Predictors\n",
    "***\n",
    "\n",
    "Ray AIR Predictors load models from your [checkpoints](https://docs.ray.io/en/latest/ray-air/key-concepts.html#air-checkpoints-doc) generated during training or tuning to perform distributed inference.\n",
    "\n",
    "During batch prediction, the input batch is converted into a Pandas DataFrame. If there is a `Preprocessor` saved in the provided `Checkpoint`, the preprocessor will be used to transform the DataFrame. The transformed DataFrame is then passed to the model for ingerence and outputted predictions will be of the same type as the original input.\n",
    "\n",
    "In *Figure 6*, you can see how `BatchPredictor` is passed a `Checkpoint` and `Predictor`.\n",
    "\n",
    "![Batch Predictor Code Snippet](../_static/assets/Introduction_to_Ray_AIR/batchpredict_code.png)\n",
    "\n",
    "*Figure 6*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AIR `BatchPredictor` for Batch Prediction\n",
    "Previously, we have trained and tuned our XGBoost model on data from June 2021. Let's now take out best checkpoint from the tuning step and perform batch inference on taxi tip data from June 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.xgboost import XGBoostPredictor\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(best_result.checkpoint, XGBoostPredictor)\n",
    "\n",
    "test_dataset = ray.data.read_parquet(\"s3://anyscale-training-data/intro-to-ray-air/nyc_taxi_2022.parquet\").drop_columns(\"is_big_tip\")\n",
    "\n",
    "predicted_probabilities = batch_predictor.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Exercise**\n",
    "\n",
    "Now that you have the predictions generated from the testing set, how did the model perform? Compare the predictions outputted by `BatchPredictor` with the ground truth labels available in the raw data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "\n",
    "print(\"PREDICTED PROBABILITIES\")\n",
    "predicted_probabilities.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts in This Section**\n",
    "\n",
    "`Checkpoints`: store the full state of the model periodically, so that partially trained models are available and can be used to resume training from an intermediate point, instead of starting from scratch; also allows for the best model to be saved for batch inference later on\n",
    "\n",
    "`BatchPredictor`: loads the best model from a checkpoint to perform batch inference on large-scales or online inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Serve\n",
    "***\n",
    "\n",
    "![Serve Highlight](../_static/assets/Introduction_to_Ray_AIR/serve_highlight.png)\n",
    "\n",
    "Finally, we want a way to serve our taxi tip prediction application to our end users, hopefully with a low latency to be maximally useful to drivers on the job. However, this poses a challenge since machine learning models are compute intensive and ideally, this model wouldn't be served in isolation, but rather adjacent to business logic or even other ML models.\n",
    "\n",
    "Ray Serve is a scalable compute layer for sercing machine learning models that allows you to serve individual models or create composite model pipelines, where you can independently deploy, update, and scale individual components. Serve isn't tied to a specific machine learning library, but rather treats models as ordinary Python code. \n",
    "\n",
    "Additionally, it allows you to flexibly combine normal Python business logic alongside machine learning models. This makes it possible to build online inference services completely end-to-end: a Serve application could validate user input, query a database, perform inference scalably across multiple ML models, and combine, filter, and validate the output all in the process of handling a single inference request.\n",
    "\n",
    "In *Figure 7*, you see the pattern for deploying a `Predictor` from a `Checkpoint` wth Ray Serve.\n",
    "\n",
    "![Ray Serve Code Snippet](../_static/assets/Introduction_to_Ray_AIR/serve_code.png)\n",
    "\n",
    "*Figure 7*\n",
    "\n",
    "Let's deploy our big tip predictor with Ray Serve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5(a) Use `PredictorDeployment` for Online Inference\n",
    "Deploy the best model as an inference service by using Ray Serve and the `PredictorDeployment` class. After deploying the service, you can send requests to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "from fastapi import Request\n",
    "from ray.serve import PredictorDeployment\n",
    "from ray.serve.http_adapters import pandas_read_json\n",
    "\n",
    "serve.run(\n",
    "    PredictorDeployment.options(name=\"XGBoostService\", num_replicas=2, route_prefix=\"/rayair\").bind(\n",
    "        XGBoostPredictor, best_result.checkpoint, http_adapter=pandas_read_json\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's send a request through HTTP. You can use the `PredictorDeployment` to deploy checkpoints trained in Ray AIR as live endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "sample_input = test_dataset.take(1)\n",
    "sample_input = dict(sample_input[0])\n",
    "\n",
    "output = requests.post(\"http://localhost:8000/rayair\", json=[sample_input]).json()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Exercise**\n",
    "\n",
    "You've just served a prediction for a single sample input from our test dataset. Predictors are able to accept array, dataframe, and custom inputs (that can be transformed to array or dataframe). You can also configure micro-batching to enhance performance.\n",
    "\n",
    "Try reading through the [user guide](https://docs.ray.io/en/latest/ray-air/examples/serving_guide.html) for predictors to accept incoming data for more than one sample and run the prediction again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "\n",
    "n = 5\n",
    "\n",
    "for i in range(n):\n",
    "    sample_input = test_dataset.take(i)\n",
    "    sample_input = dict(sample_input[0])\n",
    "\n",
    "    output = requests.post(\"http://localhost:8000/rayair\", json=[sample_input]).json()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts in This Section**\n",
    "\n",
    "`Deployments`: you can think of this as a managed group of Ray actors that can be addressed together and will handle requests load-balanced across them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Summary\n",
    "You've now just created a Ray Dataset, preprocessed some features, built a model with XGBoost, searched a hyperparameter space for the best configuration, loaded the best model from a checkpoint to perform batch inference, and served that model for online inference. Through this end-to-end example, you explored how to use Ray AIR to distribute an entire ML pipeline.\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "- `Datasets`\n",
    "- `Preprocessors`\n",
    "- `Trainers`\n",
    "- `Tuner`\n",
    "- `Checkpoints`\n",
    "- `BatchPredictor`\n",
    "- `Deployments`\n",
    "\n",
    "#### Next Up\n",
    "\n",
    "Now that you've seen how you can use Ray AIR's unified toolkit to scale an end-to-end machine learning application, let's see how we can use it to scale reinforcement learning specific workloads. In the next section we will cover a reinforcement learning example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Reinforcement Learning on Ray AIR\n",
    "\n",
    "In addition to scaling end-to-end workflows with supervised learning problems, we can use Ray AIR to scale reinforcement learning workloads. Here, we will demonstrate this by training a reinforcement learning agent using online training.\n",
    "\n",
    "**A Brief Primer on Reinforcement Learning Basics**\n",
    "\n",
    "Reinforcement learning (RL) involves an **agent** learning what to do through **rewards** based on its interactions from its **environment**. Unlike other types of machine learning, the path to maximize rewards is not prescribed, but rather must be learned through trying and feedback over time. To unpack this further, here are some key componenents of RL problem:\n",
    "\n",
    "- **Action Space** - all possible actions; could be discrete steps (left, right) or continuous (accelerate $F  \\frac{m}{s^2}$)\n",
    "- **State Space** - a complete description of the environment; a *value function* specifies the value of reward the agent can accumulate in the future starting from that state\n",
    "- **Observation Space** - an observation by the agent of certain parts of the state\n",
    "- **Reward** - feedback, positive or negative, after each action; defines the goal\n",
    "- **Policy** - defines the learning agent's way of behaving based on its expected sum over all future rewards\n",
    "\n",
    "![Agent/Env](https://www.kdnuggets.com/images/reinforcement-learning-fig1-700.jpg)\n",
    "\n",
    "We'll go into how to work with these components in the coding exercise. For now, let's chat about how to run reinforcement learning applications with Ray RLlib.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray RLLib\n",
    "***\n",
    "\n",
    "![RLlib Highlight](../_static/assets/Introduction_to_Ray_AIR/rllib_highlight.png)\n",
    "\n",
    "RLlib is an open-source library for reinforcement learning (RL), offering support for [production-level](https://www.anyscale.com/events/2021/06/23/applying-ray-and-rllib-to-real-life-industrial-use-cases), distributed RL workloads while maintaining unified and simple APIs for a large variety of industry applications. As part of the Ray ecosystem, RLlib integrates well with other Ray libraries like Ray Tune for checkpointing and Ray Serve for deploying models.\n",
    "\n",
    "**Some Key Features of RLlib:**\n",
    "\n",
    "- **[PyTorch](https://github.com/ray-project/ray/blob/master/rllib/examples/custom_torch_policy.py) and [Tensorflow](https://github.com/ray-project/ray/blob/master/rllib/examples/custom_tf_policy.py)** - available as backends, with the option to switch between them with one line of code\n",
    "- **Hightly Distributed** - inherits from Ray Core and allows you to configure `num_workers` to run on hundreds of nodes\n",
    "- **Vectorized and Remote Environments** - batched and parallel environments that auto-vectorizes `gym.Envs` via the `num_envs_per_worker` config\n",
    "- **Support for Multi-Agent** - convert custom `gym.Envs` into a multi-agent set-up to start training with cooperative policies, adversarial scenarios, and/or independent learning\n",
    "- **External Simulators** - support for external environment API and comes with a pluggable, off-the-shelf client/server setup that allows you to run hundreds of independent simulators on the \"outside\" connecting to a central RLlib Policy-Server that learns and serves actions.\n",
    "- **Offline Support** - comes with several offline algorithms (CQL, MARWIL, and DQfD) allowing either behavior-cloning an existing system or learning how to improve it\n",
    "- [**Algorithms**](https://docs.ray.io/en/latest/rllib/rllib-algorithms.html) - a growing collection of 25+ algorithms to apply in offline, model-free on-policy, model-free off-policy, model-based, derivative-free, recommender systems, contextual bandits, multi-agent, and other RL\n",
    "- [**Environments**](https://docs.ray.io/en/latest/rllib/rllib-env.html) - support for several different types of environments including OpenAI Gym, user-defined, multi-agent, and batch environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: CartPole Training and Online Evaluation\n",
    "\n",
    "For our example, we will run training on the [CartPole environment](https://www.gymlibrary.dev/environments/classic_control/cart_pole/) from [OpenAI Gym](https://www.gymlibrary.dev/). The premise is essentially that there is a pole attached to a cart on a frictionless track and the agent's job is to balance this pendulum upright by moving left and right. The observation space consists of the cart position, cart velocity, pole angle, and pole angular velocity, and the goal is to keep the pole upright for as long as possible.\n",
    "\n",
    "![Cartpole](https://www.gymlibrary.dev/_images/cart_pole.gif)\n",
    "\n",
    "*Figure 8*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from ray.air import RunConfig\n",
    "from ray.air import ScalingConfig\n",
    "\n",
    "from ray.air import Checkpoint\n",
    "from ray.air import Result\n",
    "\n",
    "from ray.train.rl import RLTrainer\n",
    "from ray.train.rl import RLPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To begin, we'll be using [OpenAI Gym](https://www.gymlibrary.dev/) which is a standard open source Python library for developing and comparing reinforcement learning algorithms as well as providing a standard set of environments.\n",
    "2. With Ray AIR's `RunConfig` and `ScalingConfig` we can specify configurations for training/tuning runs and scaling training respectively so that your settings are preserved in the pipeline.\n",
    "3. Callback to `Checkpoint` and `Result` objects from previous sections that store the state of your model and the result from a training or tuning trial.\n",
    "4. Import RL specific trainers and predictors which are able to take in Ray datasets and preprocessors from prior steps.\n",
    "\n",
    "Note: We are using a Ray AIR wrapper for RLlib's trainable which allows a smoother integration with the Ray ecosystem. For custom environments, preprocessors, or models, you can check out the [Training APIs for Rllib](https://docs.ray.io/en/latest/rllib/rllib-training.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rl(num_workers, use_gpu):\n",
    "    trainer = RLTrainer(\n",
    "        run_config=RunConfig(stop={\"training_iteration\": 5}),\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "        algorithm=\"PPO\",\n",
    "        config={\n",
    "            \"env\": \"CartPole-v1\",\n",
    "            \"framework\": \"tf\",\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    return trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a training function, `train_rl()` that takes in:\n",
    "- `num_workers`: int, the number of workers to start\n",
    "- `use_gpu`: bool, whether to use gpu\n",
    "\n",
    "and creates an `RLTrainer`, similar to the `Trainer` object we encountered in the Ray Train section, which specifies:\n",
    "\n",
    "- `RunConfig`: sets up how the training run should happen\n",
    "- `ScalingConfig`: allows you to adjust settings for how to scale training\n",
    "- `algorithm`: we use the [`PPO` algorithm](https://openai.com/blog/openai-baselines-ppo/)\n",
    "- `config`: specifies our `CartPole-v1` environment and uses Tensorflow as a our backend\n",
    "\n",
    "When we call `train_rl()`, it returns a `Result` object automatically created by `trainer.fit()` through which we can access a `Checkpoint` of the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define an Evaluation Function\n",
    "\n",
    "Next, we want to create a function to evaluate how well our model trained. It's performance will be evaluated on a reset version of the same environment. In this online evaluation technique, unlike supervised learning cases where we evaluate on a static test set, we probe how well the agent performs through a live simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(checkpoint, num_episodes):\n",
    "    predictor = RLPredictor.from_checkpoint(checkpoint)\n",
    "\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        reward = 0.0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = predictor.predict(np.array([obs]))\n",
    "            obs, r, done, _ = env.step(action[0])\n",
    "            reward += r\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an `evaluate()` function that takes in:\n",
    "- `checkpoint`: the saved model state from the training `Result`\n",
    "- `num_episodes`: the number of episodes to run, i.e. agent-environment iteration cycles\n",
    "\n",
    "To begin, we:\n",
    "\n",
    "- Create an `RLPredictor` from the `checkpoint`\n",
    "- Set the environment to `CartPole-v1`\n",
    "- Create a list of rewards for each episode\n",
    "\n",
    "For every episode:\n",
    "- `env.reset()` - the observation state is reset to a uniformly random value `(-0.05, 0.05)` for cart position, cart velocity, pole angle, and pole angular velocity\n",
    "- set `reward` to 0 and `done` flag to `False`\n",
    "\n",
    "While we're not in a terminal state:\n",
    "- take an action based on the trained model's best judgement of the observation space\n",
    "- obtain a new observation state, reward, and done flag after taking a step\n",
    "- we assign a reward of `+1` for every step taken, including the termination step\n",
    "\n",
    "<!-- **Example Terminal States**\n",
    "\n",
    "1. Termination: Pole Angle is greater than $\\pm 12 \\degree$\n",
    "2. Termination: Cart Position is greater than $\\pm2.4$ (center of the cart reaches the edge of the display)\n",
    "3. Truncation: Episode length is greater than 500 (200 for v0) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online Reinforcement Learning\n",
    "\n",
    "Finally, let's put it all together to train the model, evaluate the policy on a fresh environment (using the checkpoint from training) for `num_episodes`. For `CartPole-v1`, the reward threshold is set to `+475`, so let's see how we stack up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 3\n",
    "\n",
    "result = train_rl(num_workers=8, use_gpu=False)\n",
    "rewards = evaluate(result.checkpoint, num_episodes=num_episodes)\n",
    "\n",
    "print(f\"Average Reward Over {num_episodes} Episodes: \" f\"{np.mean(rewards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Exercise**\n",
    "\n",
    "We have mostly kept this example to focus on RLlib, but we can definitely apply our learnings from previous sections to extend this solution. RLlib integrates particularly well with Ray Tune.\n",
    "\n",
    "Modify the function `train_rl(num_workers, use_gpu)` we created above to include a tuning step. Some things that will help you along the way:\n",
    "\n",
    "- RLlib Trainers can be passed into the first argument when instantiating a `Tuner` object.\n",
    "- We want a `Checkpoint` at the end of tuning to access later on in our evaluation step, so turn this parameter to `True`\n",
    "- Remember that Tuner returns a `ResultGrid` that contains all the results from your training run. You can either elect to return the first result, or better yet, return the best result by querying `result_grid.get_best_result()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "def train_rl(num_workers, use_gpu):\n",
    "    trainer = RLTrainer(\n",
    "        run_config=RunConfig(stop={\"training_iteration\": 5}),\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "        algorithm=\"PPO\",\n",
    "        config={\n",
    "            \"env\": \"CartPole-v1\",\n",
    "            \"framework\": \"tf\",\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    ### MODIFY TRAIN_RL HERE ###\n",
    "\n",
    "    return trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "\n",
    "from ray import tune\n",
    "\n",
    "def train_rl(num_workers, use_gpu):\n",
    "    trainer = RLTrainer(\n",
    "        run_config=RunConfig(stop={\"training_iteration\": 5}),\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "        algorithm=\"PPO\",\n",
    "        config={\n",
    "            \"env\": \"CartPole-v1\",\n",
    "            \"framework\": \"tf\",\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    tuner = Tuner(\n",
    "        trainer,\n",
    "        _tuner_kwargs={\"checkpoint_at_end\": True},\n",
    "    )\n",
    "    result = tuner.fit()[0]\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Summary\n",
    "\n",
    "In this section, we trained a reinforcement learning agent using online training in a Cartpole environment.\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "Reinforcement Learning Concepts\n",
    "- Agent\n",
    "- Action Space\n",
    "- State Space\n",
    "- Observation Space\n",
    "- Reward\n",
    "- Policy\n",
    "\n",
    "#### Key RLlib Objects\n",
    "\n",
    "* `RunConfig`\n",
    "* `ScalingConfig`\n",
    "* `Checkpoint`\n",
    "* `Result`\n",
    "* `RLTrainer`\n",
    "* `RLPredictor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Resources\n",
    "\n",
    "If you would like to practice your new skills further with some in-depth examples beyond the embedded coding exercises, take a look at this list of suggested problems:\n",
    "\n",
    "* Watch the Ray Summit Talk on [Introduction to Ray AIR](https://github.com/ray-project/hackathon5-algo)\n",
    "* Check out the [Ray AIR Documentation](https://docs.ray.io/en/latest/ray-air/getting-started.html)\n",
    "* Understand its [Components and APIs](https://docs.ray.io/en/latest/ray-air/package-ref.html)\n",
    "* Ray AIR [User Guides](https://docs.ray.io/en/latest/ray-air/user-guides.html) and [Examples](https://docs.ray.io/en/latest/ray-air/examples/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect with the Ray community\n",
    "\n",
    "You can learn and get more involved with the Ray community of developers and researchers:\n",
    "\n",
    "* [Ray documentation](https://docs.ray.io/en/latest)\n",
    "* [Official Ray Website](https://www.ray.io/): Browse the ecosystem and use this site as a hub to get the information that you need to get going and building with Ray.\n",
    "* [Join the Community on Slack](https://forms.gle/9TSdDYUgxYs8SA9e8): Find friends to discuss your new learnings in our Slack space.\n",
    "* [Use the Discussion Board](https://discuss.ray.io/): Ask questions, follow topics, and view announcements on this community forum.\n",
    "* [Join a Meetup Group](https://www.meetup.com/Bay-Area-Ray-Meetup/): Tune in on meet-ups to listen to compelling talks, get to know other users, and meet the team behind Ray.\n",
    "* [Open an Issue](https://github.com/ray-project/ray/issues/new/choose): Ray is constantly evolving to improve developer experience. Submit feature requests, bug-reports, and get help via GitHub issues.\n",
    "* [Become a Ray contributor](https://docs.ray.io/en/latest/ray-contribute/getting-involved.html): We welcome community contributions to improve our documentation and Ray framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_static/assets/Generic/ray_logo.png\" width=\"20%\" loading=\"lazy\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "567405a8058597909526349386224fe35dd047505a91307e44ed44be00113429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
