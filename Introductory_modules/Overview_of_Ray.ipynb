{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Ray\n",
    "\n",
    "<img src=\"../_static/assets/Generic/ray_logo.png\" width=\"20%\" loading=\"lazy\">\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "### Is it right for you?\n",
    "\n",
    "This is an introductory notebook that gives a broad overview of the Ray project. It is right for you if:\n",
    "\n",
    "* you are new to Ray and look for a project primer\n",
    "* you are interested in how you can use Ray - Python first distributed computing library - to scale your Python applications and accelerate machine learning workloads\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "For this notebook you should have:\n",
    "\n",
    "* practical Python and machine learning experience\n",
    "* no prior experience with Ray or distributed computing\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "Upon completion of this notebook, you will know about:\n",
    "\n",
    "* what is Ray?\n",
    "* key Ray characteristics\n",
    "* three layers of the Ray libraries: Core, native libraries, and integrations and ecosystem\n",
    "* example Ray use cases and workloads\n",
    "* what to do next to start using it\n",
    "\n",
    "### What will you do?\n",
    "\n",
    "In the *Part 1* of this notebook you will learn about Ray project. Then, in *Part 2* you will run an illustrative code example that will give you better \"feel\" of Ray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Ray project\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/ray_project.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Ray is one of the leading open source ML projects. (date accessed: Nov 2, 2022)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "#### What is Ray?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://www.ray.io/\" target=\"_blank\">Ray</a></strong> is an open-source unified compute framework that makes it easy to scale AI and Python workloads.\n",
    "</div>\n",
    "\n",
    "Thanks to the Python first approach, ML engineers can parallelize Python applications on their laptop, cluster, cloud, Kubernetes, or on-premise hardware. Ray automatically handles all aspects of distributed execution including orchestration, scheduling, fault tolerance, and auto-scaling so that you can scale your apps without becoming a distributed systems expert.\n",
    "\n",
    "With a rich ecosystem of libraries and integrations with many important data science tools, Ray lowers the effort needed to scale compute intensive workloads and applications.\n",
    "\n",
    "#### Distributed computing: a bit of a context and project history\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/project_history.jpeg\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Compute demand is growing faster than supply. It exceeds progression of CPUs, GPUs and TPUs processing power. (date accessed: Nov 2, 2022)|\n",
    "\n",
    "Distributed computing is hard. At the same time it is becoming increasingly crucial and necessary for modern machine learning and AI systems.\n",
    "\n",
    "OpenAI's recent paper [AI and Compute](https://openai.com/blog/ai-and-compute/) suggests exponential growth in compute needed to train AI models. Study suggests that compute needed for AI systems has been doubling every 3.4 months since 2012.\n",
    "\n",
    "This context drove researchers to begin building solutions to simplify running code on compute clusters without having to think about how to orchestrate and utilize individual machines. That is, let Ray do the hard bit of orchestrating and executing, and you do the easy bit of writing Python code.\n",
    "\n",
    "Ray was developed at the University of California Berkeley's [RISELab](https://rise.cs.berkeley.edu/), the successor to the [AMPLab](https://amplab.cs.berkeley.edu/about/), that created [Apache Spark](https://spark.apache.org/) and [Mesos](https://mesos.apache.org/). \n",
    "\n",
    "[Anyscale](https://www.anyscale.com/), the company behind Ray, was founded by Ray creators to build a managed Ray platform and offers hosted solutions for Ray applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Ray characteristics\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/python_first.jpeg\" width=\"70%\" loading=\"lazy\">|<img src=\"../_static/assets/Overview_of_Ray/simple_and_flexible_api.jpeg\" width=\"70%\" loading=\"lazy\">|<img src=\"../_static/assets/Overview_of_Ray/scalability.jpeg\" width=\"70%\" loading=\"lazy\">|<img src=\"../_static/assets/Overview_of_Ray/heterogeneous_hardware.jpeg\" width=\"70%\" loading=\"lazy\">|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|Python first approach|Simple and Flexible API|Scalability|Support for heterogeneous hardware|\n",
    "\n",
    "#### Python first approach\n",
    "\n",
    "<img src=\"../_static/assets/Overview_of_Ray/python_first.jpeg\" width=\"100px\" loading=\"lazy\">\n",
    "\n",
    "Ray's framework provides Python library with abstractions and primitives that enables ML practitioners and Python developers to build distributed applications. Ray exposes concise and easy to use API. Its core library that enables parallel execution introduces just a few key abstractions:\n",
    "\n",
    "1. [Tasks](https://docs.ray.io/en/latest/ray-core/key-concepts.html#tasks): remote, stateless Python functions\n",
    "1. [Actors](https://docs.ray.io/en/latest/ray-core/key-concepts.html#actors): remote stateful Python classes\n",
    "1. [Objects](https://docs.ray.io/en/latest/ray-core/key-concepts.html#objects): in-memory, immutable objects or value that can be accessed anywhere in the computing cluster\n",
    "\n",
    "You will learn more about these abstractions in the [Ray Core tutorials](https://github.com/ray-project/ray-educational-materials/tree/main/Ray_Core).\n",
    "\n",
    "#### Simple and flexible API\n",
    "\n",
    "<img src=\"../_static/assets/Overview_of_Ray/simple_and_flexible_api.jpeg\" width=\"100px\" loading=\"lazy\">\n",
    "\n",
    "##### Ray Core\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-core/walkthrough.html\" target=\"_blank\">Ray Core</a></strong> is an open-source, Python, general purpose, distributed computing library that enables ML engineers and Python developers to scale Python applications and accelerate machine learning workloads.\n",
    "</div>\n",
    "\n",
    "Foundational library for the whole ecosystem - provides minimalist API that enables distributed computing. With just a few methods you can start building distributed apps.\n",
    "\n",
    "* `ray.init()` - start Ray runtime and connect to the Ray cluster\n",
    "* `@ray.remote` -  functions and classes decorator specifying that it will be executed as a task (remote function) or actor (remote class) in a different process\n",
    "* `.remote` - postfix to the remote functions and classes. Remote operations are *asynchronous*\n",
    "* `ray.put()` - put an object in the in-memory object store and return its ID. Use this ID to pass object to any remote function or method call\n",
    "* `ray.get()` - get a remote object or a list of remote objects from the object store\n",
    "\n",
    "*(In the second part of this notebook you will see illustrative example for some of these methods.)*\n",
    "\n",
    "##### Ray AI Runtime (AIR)\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-air/getting-started.html\" target=\"_blank\">Ray AI Runtime (AIR)</a></strong> is an open-source, Python, domain specific library that equips ML engineers, data scientists, and researchers with a scalable and unified toolkit for ML applications.\n",
    "</div>\n",
    "\n",
    "Ray AI Runtime (AIR) (sometimes referred to as native libraries) and ecosystem libraries, provides higher level APIs that cater for more domain specific use cases. Ray AIR enables Python developers and ML engineers to scale individual workloads, end-to-end workflows, and popular ecosystem frameworks, all in familiar Python programming language.\n",
    "\n",
    "#### Scalability\n",
    "\n",
    "<img src=\"../_static/assets/Overview_of_Ray/scalability.jpeg\" width=\"100px\" loading=\"lazy\">\n",
    "\n",
    "Ray allows their users to utilize large compute clusters in an easy, productive, and resource-efficient way.\n",
    "\n",
    "Fundamentally, Ray treats the entire cluster as a single, unified pool of resources and takes care of optimally mapping compute workloads to the pool. By doing so, Ray largely eliminates non-scalable factors in the system. Successful user stories include, but are not limited to:\n",
    "* [how Instacart uses Ray to power their large scale fulfillment ML pipline](https://www.anyscale.com/ray-summit-2022/agenda/sessions/130),\n",
    "* [how OpenAI trains their largest models](https://twitter.com/anyscalecompute/status/1562136159135973380),\n",
    "* [how companies like HuggingFace and Cohere use Ray Train for scaling model training](https://docs.ray.io/en/latest/train/train.html).\n",
    "\n",
    "Ray's [autoscaler](https://docs.ray.io/en/latest/cluster/key-concepts.html#autoscaling) implements automatic scaling of Ray clusters based on the resource demands of an application. The autoscaler will increase worker nodes when the Ray workload exceeds the cluster's capacity. Whenever worker nodes sit idle, the autoscaler will scale them down.\n",
    "\n",
    "#### Support for heterogeneous hardware\n",
    "\n",
    "<img src=\"../_static/assets/Overview_of_Ray/heterogeneous_hardware.jpeg\" width=\"100px\" loading=\"lazy\">\n",
    "\n",
    "One of the key properties of Ray is natively supporting heterogeneous hardware by allowing developers to specify such hardware when instantiating a Task or Actor. For example, a developer can specify in the same application that one Task needs 128 CPUs, while an Actor requires 36 CPUs and 8 Nvidia A100 GPUs.\n",
    "\n",
    "Fractional GPUs are also supported.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/heterogeneous_hardware_code.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Easily specify amount of resources needed, by using `num_cpus` and `num_gpus`|\n",
    "\n",
    "An illustrative example is the [production deep learning pipeline at Uber](https://www.anyscale.com/ray-summit-2022/agenda/sessions/215). A heterogeneous setup of 8 GPU nodes and 9 CPU nodes improves the pipeline throughput by 50%, while substantially saving capital cost, compared with the legacy setup of 16 GPU nodes.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/uber.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Production deep learning pipeline at Uber.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ray libraries\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/map.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Stack of Ray libraries - unified toolkit for ML workloads.|\n",
    "\n",
    "Now, you will learn about three *layers* that comprise Ray in the greater detail:\n",
    "\n",
    "1. Ray Core\n",
    "1. Ray AI Runtime (native libraries)\n",
    "1. integrations and ecosystem\n",
    "\n",
    "#### Ray clusters\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/cluster/getting-started.html\" target=\"_blank\">Ray cluster</a></strong> is a set of worker nodes connected to a common Ray head node. Ray clusters can be fixed-size, or they may autoscale up and down according to the resources requested by applications running on the cluster.\n",
    "</div>\n",
    "\n",
    "Notice that the bottom layer is [cluster](https://docs.ray.io/en/latest/cluster/getting-started.html). Ray sets up and manages clusters of computers so that you can run distributed applications on them.  You can deploy a Ray cluster on AWS, GCP or on Kubernetes via the officially supported [KubeRay](https://docs.ray.io/en/latest/cluster/kubernetes/index.html) project. Note that [Anyscale](https://www.anyscale.com/), the company behind Ray, builds enterprise-ready AI compute platform for running and managing ray applications.\n",
    "\n",
    "#### Ray Core\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-core/walkthrough.html\" target=\"_blank\">Ray Core</a></strong> is an open-source, Python, general purpose, distributed computing library that enables ML engineers and Python developers to scale Python applications and accelerate machine learning workloads.\n",
    "</div>\n",
    "\n",
    "Ray Core is a foundation that Ray's ML libraries (Ray AIR) and third-party integrations (Ray Ecosystem) are built on. This library enables Python developer to easily build scalable, distributed systems that run on your laptop, cluster, cloud or Kubernetes.\n",
    "\n",
    "Let's expand a bit on key abstractions mentioned before:\n",
    "\n",
    "1. [Tasks](https://docs.ray.io/en/latest/ray-core/key-concepts.html#tasks): remote, stateless Python functions.  \n",
    "They are arbitrary Python functions that are executed asychronously on separate Python workers on a Ray cluster nodes. User can specify their resource requirements in terms of CPUs, GPUs, and custom resources which are used by the cluster scheduler to distribute tasks for parallelized execution.\n",
    "\n",
    "1. [Actors](https://docs.ray.io/en/latest/ray-core/key-concepts.html#actors): remote stateful Python classes.  \n",
    "What tasks are to functions, actors are to classes. An actor is a stateful worker, and the methods of an actor are scheduled on that specific worker and can access and mutate the state of that worker. Like tasks, actors support CPU, GPU, and custom resource requirements.\n",
    "\n",
    "1. [Objects](https://docs.ray.io/en/latest/ray-core/key-concepts.html#objects): in-memory, immutable objects or value that can be accessed anywhere in the computing cluster.  \n",
    "In Ray, tasks and actors create and compute on objects. These remote objects can be stored anywhere in a Ray cluster. Object IDs are used to refer to them, and they are cached in Ray's distributed shared memory: object store.\n",
    "\n",
    "#### Ray AI Runtime\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-air/getting-started.html\" target=\"_blank\">Ray AI Runtime (AIR)</a></strong> is an open-source, Python, domain specific library that equips ML engineers, data scientists, and researchers with a scalable and unified toolkit for ML applications.\n",
    "</div>\n",
    "\n",
    "Ray AIR is built on top of Ray core. It caters for distributed data processing, model training, tuning, model serving, and reinforcement learning, all in Python. To that end, it enables both individual workloads and end-to-end use cases to be implemented in the single unified library.\n",
    "\n",
    "Ray AIR brings together an ever-growing ecosystem of integrations with your favorite machine learning frameworks.\n",
    "\n",
    "|<img src=\"../_static/assets/Introduction_to_Ray_AIR/e2e_air.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Ray AIR enables end-to-end ML development and provides multiple options to integrate with other tools and libraries form the MLOps ecosystem.|\n",
    "\n",
    "Each of the five native libraries that Ray AIR wraps is focused on a specific ML task. Because this abstraction layer is built on top of Ray Core, it is distributed and scalable.\n",
    "\n",
    "1. [Ray Data](https://docs.ray.io/en/latest/data/dataset.html): scalable, framework-agnostic loading and transforming raw data across training and prediction\n",
    "1. [Ray Train](https://docs.ray.io/en/latest/train/train.html): distributed multi-node and multi-core model training with fault tolerance that integrates with your favorite training libraries\n",
    "1. [Ray Tune](https://docs.ray.io/en/latest/tune/index.html): scales experiment execution and hyperparameter tuning to optimize model performance\n",
    "1. [Ray Serve](https://docs.ray.io/en/latest/serve/index.html): deploys your model for online inference, with optional microbatching to improve performance\n",
    "1. [Ray RLlib](https://docs.ray.io/en/latest/rllib/index.html): distributed reinforcement learning workloads that integrate with the other Ray AIR libraries above\n",
    "\n",
    "#### Integrations and ecosystem libraries\n",
    "\n",
    "Ray integrates with a [growing ecosystem](https://docs.ray.io/en/latest/ray-overview/ray-libraries.html) of the most popular Python and machine learning libraries and frameworks that you may already be familiar with. Instead of trying to create new standards, Ray allows you to scale existing workloads by unifying tools in a common interface. This interface enables you to run ML tasks in a distributed way, a property most of the respective backends don't have, or not to the same extent.\n",
    "\n",
    "For example, Ray Datasets is backed by Arrow and comes with many integrations to other frameworks, such as Spark and Dask. Ray Train and RLlib are backed by the full power of Tensorflow and PyTorch. Ray Tune supports algorithms from practically every noteable HPO tool available, including Hyperopt, Optuna, Nevergrad, Ax, SigOpt, and many others. Ray Serve can be used with frameworks such as FastAPI, gradio, and Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ray use cases\n",
    "\n",
    "Now that you have a sense of what Ray is in theory, it's important to discuss what makes Ray so useful in practice. In this section, you will encounter the ways that individuals, organizations, and companies leverage Ray to build their AI applications.\n",
    "\n",
    "First, you will explore how Ray scales common ML workloads before learning about some advanced implementations.\n",
    "\n",
    "#### Scaling common ML workloads\n",
    "\n",
    "##### Parallel training of many models\n",
    "When any given model you want to train can fit on a single GPU, then Ray can assign each training run to a separate Ray Task. In this way, all available workers are utilized to run independent remote functions rather than one worker running jobs sequentially.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/data_parallelism.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|A visualization of data paralleism pattern for distributed training.|\n",
    "\n",
    "##### Distributed training of large models\n",
    "In contrast to training many models, model parallelism partitions a large model across many machines for training. Ray Train has built in abstractions for this for distributing shards of models and running training in parallel.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/model_parallelism.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|A visualization of model parallelism pattern for distributed training.|\n",
    "\n",
    "##### Managing parallel hyperparameter tuning experiments\n",
    "In a similar vein, running multiple hyperparameter tuning experiments is a pattern apt for distributed computing because each model experiement is independent of the others. Ray Tune handles the hard bit of distributing your hyperparameter optimization and makes available key features such as checkpointing your best result, optimizing scheduling, specifying search patterns, and more.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/tuning_use_case.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Caption|\n",
    "\n",
    "##### Reinforcement Learning\n",
    "Ray RLlib offers support for production-level, distributed reinforcement learning workloads while maintaining unified and simple APIs for a large variety of industry applications.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/rllib_use_case.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|RLlib's algorithm classes leverage parallel iterators to implement a synchronous sampling pattern.|\n",
    "\n",
    "##### Batch inference on CPUs and GPUs\n",
    "Performing inference on batches of new data can be parallelized by exporting the architecture and weights of a trained model to the shared object store and allowing Ray to handle assignment of predictions to be executed on the batches.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/batch_inference.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Using Ray AIR's `BatchPredictor` for batch inference.|\n",
    "\n",
    "##### Multi-model composition for model serving\n",
    "\n",
    "[Ray Serve](https://docs.ray.io/en/latest/serve/index.html) supports complex [model deployment patterns](https://www.anyscale.com/ray-summit-2022/agenda/sessions/224) requiring the orchestration of multiple Ray actors, where different actors provide inference for different models. It handles both batch and online inference and can scale to thousands of models in production.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/multi_model_serve.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Deployment patterns with Ray Serve.|\n",
    "\n",
    "##### ML Platform\n",
    "\n",
    "[Merlin](https://shopify.engineering/merlin-shopify-machine-learning-platform) is a Shopify's ML platform built on Ray. It enables fast-iteration and [scaling of distributed applications](https://www.anyscale.com/ray-summit-2022/agenda/sessions/171) such as product categorization and recommendations.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/shopify.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Merlin architecture built on Ray.|\n",
    "\n",
    "Spotify [uses Ray for advanced applications](https://www.anyscale.com/ray-summit-2022/agenda/sessions/180)] that include personalizing content recommendations for home podcasts and personalizing Spotify Radio track sequencing.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/spotify.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|How Ray ecosystem powers ML scientists and engineers at Spotify.|\n",
    "\n",
    "#### Implementing advanced ML workloads\n",
    "\n",
    "##### Alpa - training very large models with Ray\n",
    "\n",
    "[Alpa](https://ai.googleblog.com/2022/05/alpa-automated-model-parallel-deep.html) is a [Ray-native library](https://www.anyscale.com/ray-summit-2022/agenda/sessions/170) that automatically partitions, schedules, and executes the training and serving computation of very large deep learning models on hundreds of GPUs.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/alpa.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Parallelization plans for a computational graph from Alpa. A, B, C, and D are operators. Each color represents a different device (i.e. GPU) executing a partition or the full operator leveraging Ray actors.|\n",
    "\n",
    "##### Exoshuffle - large scale data shuffling\n",
    "\n",
    "In Ray 2.0, [Exoshuffle](https://cs.paperswithcode.com/paper/exoshuffle-large-scale-shuffle-at-the) is integrated with the Ray Data to provide an application level shuffle system that [outperforms Spark and achieves 82% of theoretical performance on a 100TB sort on 100 nodes](https://www.anyscale.com/ray-summit-2022/agenda/sessions/220).\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/exoshuffle.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Shuffle on Ray architecture diagram.|\n",
    "\n",
    "##### Hamilton - feature engineering\n",
    "\n",
    "[Hamilton](https://github.com/stitchfix/hamilton) is an open source dataflow micro-framework that manages feature engineering for time series forecasting. Library developed at [StitchFix](https://www.anyscale.com/ray-summit-2022/agenda/sessions/115), it provides scalable parallelism, where each Hamilton function is distributed and data is limited by machine memory.\n",
    "\n",
    "Integration with Ray provides an out-of-the-box experience.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/stitchfix.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Hamilton architecture on Ray clusters.|\n",
    "\n",
    "##### Riot Games - reinforcement learning\n",
    "\n",
    "Riot Games reinforcement learning platform built on Ray drives [key AI applications](https://www.anyscale.com/ray-summit-2022/agenda/sessions/148) that builds bots to play their games at various skill levels to provide additional signals to their designers to deliver the best experiences for players.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/riot.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Riot reinforcement learning workflow on Ray.|\n",
    "\n",
    "##### FIFA - reinforcement learning\n",
    "\n",
    "Ray is powering reinforcement learning applications for [FIFA World Cup Qatar 2022](https://www.anyscale.com/ray-summit-2022/agenda/sessions/177) including optimizing the flow of millions of fans, managing vehicle traffic, and modeling congestion scenarios.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/fifa.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Speeding up agent training with Ray demonstrating faster convergence.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the part 1\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/map_layers_only.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Stack of Ray libraries - unified toolkit for ML workloads.|\n",
    "\n",
    "You just learned about:\n",
    "\n",
    "* what is Ray?\n",
    "* key Ray characteristics\n",
    "* three layers of the Ray libraries: Core, native libraries, and integrations and ecosystem\n",
    "* example Ray use cases and workloads\n",
    "\n",
    "#### Concepts\n",
    "\n",
    "Let's revisit key concepts introduced in Part 1:\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://www.ray.io/\" target=\"_blank\">Ray</a></strong> is an open-source unified compute framework that makes it easy to scale AI and Python workloads.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/cluster/getting-started.html\" target=\"_blank\">Ray cluster</a></strong> is a set of worker nodes connected to a common Ray head node. Ray clusters can be fixed-size, or they may autoscale up and down according to the resources requested by applications running on the cluster.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-core/walkthrough.html\" target=\"_blank\">Ray Core</a></strong> is an open-source, Python, general purpose, distributed computing library that enables ML engineers and Python developers to scale Python applications and accelerate machine learning workloads.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-air/getting-started.html\" target=\"_blank\">Ray AI Runtime (AIR)</a></strong> is an open-source, Python, domain specific library that equips ML engineers, data scientists, and researchers with a scalable and unified toolkit for ML applications.\n",
    "</div>\n",
    "\n",
    "#### APIs and technical abstractions\n",
    "\n",
    "Let's revisit Ray Core three abstractions that enables parrallel computations:\n",
    "\n",
    "1. [Tasks](https://docs.ray.io/en/latest/ray-core/key-concepts.html#tasks): remote, stateless Python functions\n",
    "1. [Actors](https://docs.ray.io/en/latest/ray-core/key-concepts.html#actors): remote stateful Python classes\n",
    "1. [Objects](https://docs.ray.io/en/latest/ray-core/key-concepts.html#objects): in-memory, immutable objects or value that can be accessed anywhere in the computing cluster\n",
    "\n",
    "#### What's next?\n",
    "\n",
    "You will run an illustrative code example that will give you better \"feel\" of Ray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Hands-on code example - scaling regression with Ray Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this section, you will run an illustrative code example that will give you better \"feel\" of Ray. Specifically, you will use Ray Core to scale a bare bones version of a common ML task: regression on the structured data.\n",
    "\n",
    "#### Data\n",
    "\n",
    "Dataset is [California House Prices](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) as available via scikit-learn.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/California_dataset.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|`n_samples = 20640`, target is numeric and corresponds to the average house value in units of 100k.|\n",
    "\n",
    "#### Model and task\n",
    "\n",
    "You will train and score [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) models using [mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) metric.\n",
    "\n",
    "In order to find the best performing model you will train many models with varying `n_estimators` hyper-parameter. This brings the topic of sequential vs. parallel model training. You will first first implement the sequential approach, then improve it by distributing training with Ray Core - you will achieve better performance and faster model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential implementation\n",
    "\n",
    "Vanilla implementation assumes sequential training. Models are trained one by one in the sequential way, as depicted on the diagram below. \n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/sequential_timeline.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Timeline of sequential tasks, one after the other.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "from operator import itemgetter\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set number of models to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will train `num_models` in both sequential and parallel scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement function to train and score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_score_model(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    n_estimators: int,\n",
    "):\n",
    "    start_time = time.time()  # measure wall time for single model training\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, random_state=201)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    time_delta = time.time() - start_time\n",
    "    print(f\"n_estimators={n_estimators}, mse={score:.4f}, took: {time_delta:.2f} seconds\")\n",
    "\n",
    "    return n_estimators, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes data, instantiates `RandomForestRegressor` model, trains it and scores the model on the test set.\n",
    "\n",
    "Function returns tuple:\n",
    "```\n",
    "(n_estimators, mse_score)\n",
    "```\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "(100, 0.2596393978947323)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement function that runs **sequential** model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sequential(n_models: int):\n",
    "    return [\n",
    "        train_and_score_model(\n",
    "            X_train=X_tr,\n",
    "            X_test=X_te,\n",
    "            y_train=y_tr,\n",
    "            y_test=y_te,\n",
    "            n_estimators=100 + 5 * j,\n",
    "        )\n",
    "        for j in range(n_models)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function train `n_models` sequentially for the increasing number of `n_estimators` (it increases by 5 for each model, so 100, 105, 110, 115, ...). \n",
    "\n",
    "Function returns list of tuples:\n",
    "```\n",
    "[(n_estimators, mse_score), (n_estimators, mse_score), ...]\n",
    "```\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "[(100, 0.2596393978947323), (105, 0.26009608813335056), (110, 0.25980497900048843), (115, 0.2595780807428954), (120, 0.2600438515882204)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run sequential model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mse_scores = run_sequential(n_models=NUM_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: wall time on the M1 MacBook Pro: 3min 7s (187s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = min(mse_scores, key=itemgetter(1))\n",
    "print(f\"Best model: mse={best[1]:.4f}, n_estimators={best[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training completed, but performance is slow due to sequential nature of model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel implementation\n",
    "\n",
    "Now, you use Ray to train these models in parallel, utilizing all available resources. Diagram below gives visual intuition for this setup.\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/distributed_timeline.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Sample timeline with ten tasks running across 4 worker nodes in parallel with minor overhead from scheduler.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Ray runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Ray\n",
    "import ray\n",
    "\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "\n",
    "cluster_info = ray.init()\n",
    "cluster_info.address_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `ray.init()` starts Ray runtime on the compute cluster.\n",
    "* with `ray.is_initialized` you make sure that you have only one Ray cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put data in the object store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_ref = ray.put(X_tr)\n",
    "X_te_ref = ray.put(X_te)\n",
    "y_tr_ref = ray.put(y_tr)\n",
    "y_te_ref = ray.put(y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your data is now available for all remote Tasks and Actors in the cluster. You use Object ID to reference the object when needed.\n",
    "\n",
    "Example Object ID look like this:\n",
    "\n",
    "`ObjectRef(00ffffffffffffffffffffffffffffffffffffff0100000002000000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement function to train and score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def train_and_score_model(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    n_estimators: int,\n",
    "):\n",
    "    start_time = time.time()  # measure wall time for single model training\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, random_state=201)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    time_delta = time.time() - start_time\n",
    "    print(f\"n_estimators={n_estimators}, mse={score:.4f}, took: {time_delta:.2f} seconds\")\n",
    "\n",
    "    return n_estimators, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is exactly the same function as in the sequential example\n",
    "* You added `@ray.remote` decorator to specify that this function will be executed as a remote task in a different process (remotely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement function that runs **parallel** model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parallel(n_models: int):\n",
    "    return ray.get(\n",
    "        [\n",
    "            train_and_score_model.remote(\n",
    "                X_train=X_tr_ref,\n",
    "                X_test=X_te_ref,\n",
    "                y_train=y_tr_ref,\n",
    "                y_test=y_te_ref,\n",
    "                n_estimators=100 + 5 * j,\n",
    "            )\n",
    "            for j in range(n_models)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You modified `run_sequential()` function to achieve parallel execution.\n",
    "\n",
    "**Remote Tasks**\n",
    "\n",
    "* Functions with `.remote` (as in the code above) suffix returns an `ObjectRef` associated with the computations to be done.\n",
    "* When you run a remote function (Ray Task), it will immediately return an `ObjectRef` (Object Reference). It is a *promise* of future work (Python futures), meaning that the task is delegated to a worker, and `ObjectRef` is returned while the task executes in the background. This is an asynchronous operation.\n",
    "* To access the expected output, you call `ray.get()` (as in the code above) on the `ObjectRef` or list of `ObjectRef`. It is a synchronous operation (blocking call). In other words: Use `ray.get()` on the returned list of `ObjectRef` to get remote objects from the object store.\n",
    "\n",
    "Operation:\n",
    "\n",
    "```\n",
    "ray.get([ObjectRef, ObjectRef, ObjectRef, ...])\n",
    "```\n",
    "\n",
    "returns list of `(n_estimators, score)` tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run parallel model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mse_scores = run_parallel(n_models=NUM_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice **7x performance gain**\n",
    "\n",
    "* Parallel: 25s.\n",
    "* Sequential: 3min 7s (187s).\n",
    "\n",
    "\n",
    "*(experiment on the M1 MacBook Pro)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = min(mse_scores, key=itemgetter(1))\n",
    "print(f\"Best model: mse={best[1]:.4f}, n_estimators={best[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training completed, with **7x performance gain** due to parallel execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shutdown Ray runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disconnect the worker, and terminate processes started by `ray.init()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the part 2: code example\n",
    "\n",
    "You achieved significant performance gain by introducing parallel model training. You adapted sequential model training computational job to run in parallel by using Ray Core API.\n",
    "\n",
    "With Ray you parallelized training without having to implement orchestration, fault tolerance or autoscaling component that requires specialized knowledge of distributed systems.\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "* [Tasks](https://docs.ray.io/en/latest/ray-core/key-concepts.html#tasks): remote, stateless Python functions\n",
    "* [Actors](https://docs.ray.io/en/latest/ray-core/key-concepts.html#actors): remote stateful Python classes\n",
    "* [Objects](https://docs.ray.io/en/latest/ray-core/key-concepts.html#objects): in-memory, immutable objects or value that can be accessed anywhere in the computing cluster\n",
    "\n",
    "#### Key API Elements\n",
    "\n",
    "* `ray.init()` - start Ray runtime and connect to the Ray cluster\n",
    "* `@ray.remote` -  functions and classes decorator specifying that it will be executed as a task (remote function) or actor (remote class) in a different process\n",
    "* `.remote` - postfix to the remote functions and classes. Remote operations are *asynchronous*\n",
    "* `ray.put()` - put an object in the in-memory object store and return its ID. Use this ID to pass object to any remote function or method call\n",
    "* `ray.get()` - get a remote object or a list of remote objects from the object store (synchronous operation)\n",
    "\n",
    "|<img src=\"../_static/assets/Overview_of_Ray/side_by_side.png\" width=\"100%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Schematic illustration of the code changes needed to create distributed Ray remote tasks.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect with the Ray community\n",
    "\n",
    "You can learn and get more involved with the Ray community of developers and researchers:\n",
    "\n",
    "* [Ray documentation](https://docs.ray.io/en/latest)\n",
    "* [Official Ray Website](https://www.ray.io/): Browse the ecosystem and use this site as a hub to get the information that you need to get going and building with Ray.\n",
    "* [Join the Community on Slack](https://forms.gle/9TSdDYUgxYs8SA9e8): Find friends to discuss your new learnings in our Slack space.\n",
    "* [Use the Discussion Board](https://discuss.ray.io/): Ask questions, follow topics, and view announcements on this community forum.\n",
    "* [Join a Meetup Group](https://www.meetup.com/Bay-Area-Ray-Meetup/): Tune in on meet-ups to listen to compelling talks, get to know other users, and meet the team behind Ray.\n",
    "* [Open an Issue](https://github.com/ray-project/ray/issues/new/choose): Ray is constantly evolving to improve developer experience. Submit feature requests, bug-reports, and get help via GitHub issues.\n",
    "* [Become a Ray contributor](https://docs.ray.io/en/latest/ray-contribute/getting-involved.html): We welcome community contributions to improve our documentation and Ray framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_static/assets/Generic/ray_logo.png\" width=\"20%\" loading=\"lazy\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "567405a8058597909526349386224fe35dd047505a91307e44ed44be00113429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
