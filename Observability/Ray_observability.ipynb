{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Observability Part 1\n",
    "\n",
    "<img src=\"../_static/assets/Generic/ray_logo.png\" width=\"20%\" loading=\"lazy\">\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "### Is this module right for you?\n",
    "\n",
    "This module provides a general purpose introduction to the most common observability tools to effectively debug, optimize, and monitor Ray applications. It is for data scientists, ML  practitioners, ML engineers, and Python developers looking for ways to understand the behavior of their Ray systems.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "For this notebook, you should satisfy the following minimum requirements:\n",
    "\n",
    "-   Practical Python experience\n",
    "-   Familiarity with Ray equivalent to completing these training modules:\n",
    "    -   [Overview of Ray](https://github.com/ray-project/ray-educational-materials/blob/main/Introductory_modules/Overview_of_Ray.ipynb)\n",
    "    -   [Ray Core](https://github.com/ray-project/ray-educational-materials/tree/main/Ray_Core)\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "-   Understand the major tools available for observability with Ray, namely the State API and Dashboard UI.\n",
    "-   Debug a sample application and surface errors through multiple different observability points.\n",
    "-   Optimize an application with a known anti-pattern and identify the bottleneck using Ray Dashboard, and implement a common design pattern to address it.\n",
    "\n",
    "### What will you do?\n",
    "\n",
    "-   Introduction to the Ray observability toolbox\n",
    "    -   Learn about what observability is and why it can be so difficult in distributed settings.\n",
    "    -   Read about the State API and Dashboard UI and leverage them in common development workflows.\n",
    "-   Ray observability workflows\n",
    "    -   Debugging\n",
    "        -   Reproduce an out of memory error and retrieve metrics and logs related to the failure.\n",
    "        -   Reproduce a hanging bug and observe its behavior.\n",
    "    -   Optimizing\n",
    "        -   Run some `ray.get()` anti-patterns and observe performance bottlenecks and implement the corresponding design pattern to optimize it.\n",
    "-   Summarize the most common observability tools and find resources for further advanced exploration.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to observability in distributed systems\n",
    "\n",
    "---\n",
    "\n",
    "Effective debugging and optimizing is crucial in any system, but it becomes even more vital in [distributed settings](https://en.wikipedia.org/wiki/Distributed_computing). With a high number of inter-connected, heterogeneous components, updates can cause opaque failures, making it difficult to identify and fix issues. The goal of observability is to allow for the monitoring and understanding of the internal state of the system in real-time to ensure its stability and performance.\n",
    "\n",
    "### What is observability?\n",
    "\n",
    "### Definitions\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong>Observability:</a></strong> the ability to understand the behavior of the internal state of a system inferred from its external outputs.\n",
    "</div>\n",
    "\n",
    "Within the context of Ray, [observability](https://docs.ray.io/en/latest/ray-observability/index.html) refers to the extent of visibility into distributed applications along with the available tools for inspecting and aggregating performance data.\n",
    "\n",
    "### Why is observability challenging in distributed systems?\n",
    "To illustrate the significance of being able to access outputted information through user-friendly tools, consider the [architecture](https://docs.google.com/document/d/1tBw9A4j62ruI5omIJbMxly-la5w4q_TjyJgJL_jN2fI/preview) of a typical Ray application in the following example code snippet:\n",
    "\n",
    "|<img src=\"../_static/assets/Introduction_to_Ray_AIR/e2e_air.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Simplified Ray application used for multi-model training on many data batches. The key takeaway is to highlight the scale of coordinating individual machines in a large distributed system, with each introducing an opportunity for failure.|\n",
    "\n",
    "A [Ray cluster](https://docs.ray.io/en/latest/cluster/key-concepts.html) consists of a head node that manages a large number of worker nodes which execute the code of an application. As the scale of the cluster increases, so does the number of [tasks](https://docs.ray.io/en/latest/ray-core/tasks.html#ray-remote-functions), [actors](https://docs.ray.io/en/latest/ray-core/actors.html#actor-guide), and [objects](https://docs.ray.io/en/latest/ray-core/objects.html#objects-in-ray) that are concurrently executed and [stored across heterogeneous machines](https://docs.ray.io/en/latest/ray-core/scheduling/memory-management.html#memory).\n",
    "\n",
    "|<img src=\"../_static/assets/Introduction_to_Ray_AIR/e2e_air.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Actor failure in a Ray cluster with millions of concurrent tasks among [thousands of worker nodes](https://github.com/ray-project/ray/blob/master/release/benchmarks/README.md).|\n",
    "\n",
    "Debugging issues in this environment can be challenging. Among [thousands of nodes and tens of thousands of actors](https://github.com/ray-project/ray/blob/master/release/benchmarks/README.md), performance bottlenecks, failures, and unpredictable behavior are inevitable. For example, diagnosing a cluster with thousands of actors and millions of processes could contain any number of non-trivial pitfalls:\n",
    "\n",
    "-   How do I know if an actor has failed, especially if the actor failed to initialize in the first place?\n",
    "    -   Some processes may become stuck indefinitely due to incomplete scheduling, known as \"hang.\"\n",
    "-   When I become aware of actor failure(s), how do I know which one(s) caused the issue?\n",
    "    -   In a set-up of tens of thousands of actors, how do I begin to identify the culprit?\n",
    "-   Once I know which actor(s) to inspect, how can I find the log and fix the bug?\n",
    "    -   Filtering through logs and tracing failures is impossible without robust tooling.\n",
    "\n",
    "The [Ray runtime](https://docs.ray.io/en/latest/ray-core/starting-ray.html#what-is-the-ray-runtime) manages much of the low-level system behavior in a Ray application which poses a unique opportunity to offer built-in performance data. By providing the right tools to successfully debug, optimize, and monitor Ray applications, developers can troubleshoot issues to improve a system's overall reliability and efficiency."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray observability toolbox\n",
    "\n",
    "---\n",
    "\n",
    "### Observability tooling by layer\n",
    "\n",
    "|<img src=\"../_static/assets/Introduction_to_Ray_AIR/e2e_air.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Ray offers observability tooling and third-party integrations at each layer of development that allow you to understand the Ray cluster, Ray application, and ML application.|\n",
    "\n",
    "| Layer | Tooling | Purpose | Scenarios |\n",
    "|---|---|---|---|\n",
    "| **Ray Cluster** | <ul><li>State API</li><li>Ray Dashboard</li></ul> | Infrastructure observability, like [`htop`](https://htop.dev/) for a Ray cluster. Monitor the status and utilization including hardware (CPUs, GPUs, TPUs), network, and memory. | Which nodes in my Ray cluster are experiencing high CPU or memory usage so that I can optimize consumption and reduce costs? |\n",
    "| **Ray Application (Core and AIR)** | <ul><li>State API</li><li>Ray Dashboard</li><li>Profiler</li><li>Debugger</li></ul> | Debug, optimize, and monitor Ray applications including the status of tasks, actors, objects, placement groups, jobs, and more. | Are my thousands of in-flight tasks and actors progressing normally, or are some failing or hanging in unintended ways? If so, which ones, and how can I access the logs easily for any given node? |\n",
    "| **ML Application** | Interactive Development <ul><li>[Weights & Biases](https://www.anyscale.com/events/2023/01/19/simplify-building-scaling-tracking-and-monitoring-your-ai-ml-models)</li><li>[MLflow](https://docs.ray.io/en/latest/tune/examples/tune-mlflow.html)</li><li>[Comet](https://docs.ray.io/en/latest/tune/examples/tune-comet.html)</li></ul> Production <ul><li>[Ray Dashboard](https://docs.ray.io/en/latest/ray-observability/ray-metrics.html)</li><li>[Arize](https://www.anyscale.com/events/2023/02/07/productionizing-machine-learning-with-observability-quality-and-flexibility)</li><li>[WhyLabs](https://docs.whylabs.ai/docs/ray-integration/)</li></ul> | Monitor ML models in interactive development and production through third-party integrations. | Which hyperparameters are optimal for my model? How does model performance vary over time or across different input data? Are there any anomalies in the model’s behavior in production?  |\n",
    "\n",
    "This section provides a solid introduction to the two main observability tools in Ray: the [State API](https://docs.ray.io/en/master/ray-observability/state/state-api.html) and the [Dashboard UI](https://docs.ray.io/en/master/ray-core/ray-dashboard.html). To demonstrate their functionality, consider the following simple example to practice on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def task():\n",
    "    time.sleep(60)\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "class Actor:\n",
    "    def call(self):\n",
    "        print(\"Actor called.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State API\n",
    "\n",
    "[State APIs](https://docs.ray.io/en/latest/ray-observability/state/state-api.html#monitoring-ray-states) allow users to access the current state of resources of Ray through [CLI](https://docs.ray.io/en/latest/ray-observability/state/cli.html#state-api-cli-ref) or [Python SDK](https://docs.ray.io/en/latest/ray-observability/state/ray-state-api-reference.html#state-api-ref).\n",
    "\n",
    "-   **Resources** include Ray tasks, actors, objects, placement groups, and more.\n",
    "-   **States** refer to the immutable metadata (e.g. actor's name) and mutable states (e.g. actor's scheduling state or pid) of Ray resources.\n",
    "\n",
    "There are three main APIs that allow you to inspect cluster resources with varying levels of granularity:\n",
    "\n",
    "-   **`summary`** returns a summarized view of a given resource (i.e. tasks, actors, objects).\n",
    "-   **`list`** returns a list of resources filterable by type and state.\n",
    "-   **`get`** returns information about a specific resource in detail.\n",
    "\n",
    "In addition, you can also easily retrieve and filter through [ray logs](https://docs.ray.io/en/latest/ray-observability/state/cli.html#ray-logs-api-cli-ref):\n",
    "\n",
    "-   **`logs`** returns the logs of tasks, actors, workers, or system log files.\n",
    "\n",
    "#### Example: Inspect cluster resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ray summary tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.call.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ray list actors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coding exercise\n",
    "\n",
    "Access more information about the actor you just created by using `ray get <actor_id>` using [CLI](https://docs.ray.io/en/latest/ray-observability/state/cli.html#ray-get) or [Python SDK](https://docs.ray.io/en/latest/ray-observability/state/ray-state-api-reference.html#get-apis) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "!ray get a913f6c55fe74f67bdf5f1b701000000 # Replace with your actor_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard UI\n",
    "\n",
    "The [Ray Dashboard](https://docs.ray.io/en/master/ray-core/ray-dashboard.html) offers a built-in mechanism for viewing the state of cluster resources, [time series](https://en.wikipedia.org/wiki/Time_series) metrics, and other features at a glance. Information made available via the terminal with the State API is also available to view in the Dashboard UI. You can access the dashboard in a few ways:\n",
    "\n",
    "-   Through the URL printed when Ray is initialized (the default is <https://localhost:8265>).\n",
    "-   When using the [cluster launcher](https://docs.ray.io/en/master/cluster/vms/references/ray-cluster-cli.html#monitor-cluster).\n",
    "-   Under the \"Tools\" tab in the [Anyscale Console](https://www.anyscale.com/platform) (all built-in; no setup).\\\n",
    "\n",
    "Note: In the Anyscale console, time series metrics are built-in, so you don't have to set anything up. Otherwise, download and configuration instructions for integration with Prometheus and Grafana can be found [here](https://docs.ray.io/en/latest/ray-observability/ray-metrics.html#ray-metrics).\n",
    "\n",
    "|<img src=\"../_static/assets/Introduction_to_Ray_AIR/e2e_air.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Ray dashboard is a web-based UI to help users monitor their cluster that acts as a central hub for the best observability tools available for Ray.|\n",
    "\n",
    "#### Dashboard Navigation\n",
    "\n",
    "The overview page of the dashboard offers live monitoring and quick links to common views such as metrics, nodes, jobs, and events related to [Ray job submission APIs](https://docs.ray.io/en/master/cluster/running-applications/job-submission/quickstart.html#jobs-quickstart) and the [Ray autoscaler](https://docs.ray.io/en/master/cluster/key-concepts.html#cluster-autoscaler). Along the top navigation bar, you will find five viewing displays:\n",
    "\n",
    "1.  **Jobs** - View the status and logs of [Ray jobs](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html#jobs-overview).\n",
    "2.  **Cluster** - View state, resource utilization, and logs for each node and worker.\n",
    "3.  **Actors** - View information about the actors that have existed on the Ray cluster.\n",
    "4.  **Metrics** - View time series metrics that automatically refresh every 15 seconds; requires [Prometheus](https://prometheus.io/) and [Grafana](https://grafana.com/oss/grafana/) running for your cluster.\n",
    "5.  **Logs** - View all logs, organized by node and file name; supports filter and search.\n",
    "\n",
    "Each view offers plenty of categories to monitor, and you can refer to the [dashboard references](https://docs.ray.io/en/latest/ray-core/ray-dashboard.html#references) for a more complete description. A more detailed investigation will come in the coming sections on Ray observability workflows.\n",
    "\n",
    "#### Coding exercise\n",
    "\n",
    "Open up the Ray Dashboard from the URL provided when you called `ray.init()`.\n",
    "\n",
    "Try running a task or creating a new actor. You can use the basic task or actor provided in the beginning of this section or set up custom ones. Monitor the updating displays to see states and access logs.\\\n",
    "Remember: In the Anyscale console, time series metrics are built-in, so you don't have to set anything up. If you're following along locally, download and configuration instructions for integration with Prometheus and Grafana can be found [here](https://docs.ray.io/en/latest/ray-observability/ray-metrics.html#ray-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.remote()\n",
    "sample_actor = Actor.remote()\n",
    "sample_actor.call.remote()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other tools\n",
    "\n",
    "Currently, the number and quality of observability tools available is under [active development](https://docs.google.com/document/d/1-MrNNgVRFld_BTUoDibX_b7alDSDzqV6rGcyhb5BP70/edit#). The following features will be covered in later modules, but they are worth mentioning here to give you a comprehensive idea of what is possible.\n",
    "\n",
    "#### Profiling\n",
    "\n",
    "You can use Python's native [cProfile module](https://docs.python.org/3/library/profile.html#module-cProfile) to profile the performance of your Ray application. For example, by [profiling Ray Actors](https://docs.ray.io/en/latest/ray-observability/monitoring-debugging/profiling.html#profiling-ray-actors-with-cprofile) with cProfile, you can look at the total runtime of each loop function, list the number of calls made, and print the execution time of all function calls. In addition, profiling is supported within the Ray Dashboard by providing built-in [stack traces and flame graphs](https://docs.ray.io/en/master/ray-observability/monitoring-debugging/profiling.html#python-cpu-profiling-in-the-dashboard) for running jobs.\n",
    "\n",
    "#### Debugger\n",
    "\n",
    "Ray supports a [built-in debugger](https://docs.ray.io/en/latest/ray-observability/ray-debugging.html#ray-debugger) that allows you to set a breakpoint that opens a PDB session. From there, you may inspect variables, step within a task or actor, and move within the stack.\n",
    "\n",
    "|<img src=\"../_static/assets/Introduction_to_Ray_AIR/e2e_air.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|The Ray debugger allows you to set breakpoints and drop into a PDB session.|\n",
    "\n",
    "### Summary\n",
    "\n",
    "#### Key concepts\n",
    "\n",
    "-   **State API**\n",
    "    -   A way to inspect the state of resources through CLI and Python SDK.\n",
    "-   **Dashboard UI** \n",
    "    -   A central way to view resources, state, and time series metrics at a glance; a great entry point to using the best support observability tools in Ray.\n",
    "-   **Other tools**\n",
    "    -   Profiling\n",
    "    -   Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running = False  # Set to True to run the memory leaker.\n",
    "\n",
    "\n",
    "@ray.remote(max_retries=0)\n",
    "def memory_leaker():\n",
    "    chunks = []\n",
    "    bytes_per_chunk = 1024 * 1024 * 1024  # 1 gigabyte.\n",
    "    while running:\n",
    "        chunks.append([0] * bytes_per_chunk)\n",
    "        time.sleep(5)  # Delay to observe the leak.\n",
    "\n",
    "\n",
    "ray.get(memory_leaker.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE STARTER SCRIPT ###\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "class Leaker:\n",
    "    def __init__(self):\n",
    "        self.leaks = []\n",
    "\n",
    "    def allocate(self, num_bytes: int, sleep_time_s: int):\n",
    "        # Each element in the array occupies 8 bytes.\n",
    "        new_list = [0] * ceil(num_bytes / 8)\n",
    "        self.leaks.append(new_list)\n",
    "\n",
    "        time.sleep(sleep_time_s)\n",
    "\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def long_running_task():\n",
    "    time.sleep(random.randint(10, 60))\n",
    "\n",
    "@ray.remote\n",
    "def dependent_task(dependencies: list[ray._raylet.ObjectRef]):\n",
    "    ray.get(dependencies)\n",
    "\n",
    "dependencies = [long_running_task.remote() for _ in range(100)]\n",
    "dependent_task.remote(dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def sleep_task(i: int) -> int:\n",
    "    time.sleep(i)\n",
    "    return i\n",
    "\n",
    "\n",
    "def post_processing_step(new_val: int):\n",
    "    time.sleep(0.5)\n",
    "\n",
    "\n",
    "big_sleep_times = [10]\n",
    "small_sleep_times = [random.random() for _ in range(20)]\n",
    "SLEEP_TIMES = big_sleep_times + small_sleep_times\n",
    "\n",
    "# Launch remote tasks\n",
    "refs = [sleep_task.remote(i) for i in SLEEP_TIMES]\n",
    "for ref in refs:\n",
    "    # Blocks until this ObjectRef is ready.\n",
    "    result = ray.get(ref)  # Retrieve result in submission order.\n",
    "    post_processing_step(result)  # Process the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "\n",
    "# Launch remote tasks.\n",
    "refs = [sleep_task.remote(i) for i in SLEEP_TIMES]\n",
    "unfinished = refs\n",
    "while unfinished:\n",
    "    # Returns the first ObjectRef that is ready.\n",
    "    finished, unfinished = ray.wait(unfinished, num_returns=1)\n",
    "    # Retrieve the first ready result.\n",
    "    result = ray.get(finished[0])\n",
    "    # Process the result.\n",
    "    post_processing_step(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f(i: int) -> int:\n",
    "    return i\n",
    "\n",
    "# Anti-pattern: no parallelism due to calling ray.get inside of the loop.\n",
    "sequential_returns = []\n",
    "for i in range(100):\n",
    "    sequential_returns.append(ray.get(f.remote(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE IMPLEMENTATION ###\n",
    "refs = []\n",
    "for i in range(100):\n",
    "    refs.append(f.remote(i))\n",
    "\n",
    "parallel_returns = ray.get(refs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect with the Ray community\n",
    "\n",
    "You can learn and get more involved with the Ray community of developers and researchers:\n",
    "\n",
    "* [**Ray documentation**](https://docs.ray.io/en/latest)\n",
    "\n",
    "* [**Official Ray site**](https://www.ray.io/)  \n",
    "Browse the ecosystem and use this site as a hub to get the information that you need to get going and building with Ray.\n",
    "\n",
    "* [**Join the community on Slack**](https://forms.gle/9TSdDYUgxYs8SA9e8)  \n",
    "Find friends to discuss your new learnings in our Slack space.\n",
    "\n",
    "* [**Use the discussion board**](https://discuss.ray.io/)  \n",
    "Ask questions, follow topics, and view announcements on this community forum.\n",
    "\n",
    "* [**Join a meetup group**](https://www.meetup.com/Bay-Area-Ray-Meetup/)  \n",
    "Tune in on meet-ups to listen to compelling talks, get to know other users, and meet the team behind Ray.\n",
    "\n",
    "* [**Open an issue**](https://github.com/ray-project/ray/issues/new/choose)  \n",
    "Ray is constantly evolving to improve developer experience. Submit feature requests, bug-reports, and get help via GitHub issues.\n",
    "\n",
    "* [**Become a Ray contributor**](https://docs.ray.io/en/latest/ray-contribute/getting-involved.html)  \n",
    "We welcome community contributions to improve our documentation and Ray framework.\n",
    "\n",
    "<img src=\"../_static/assets/Generic/ray_logo.png\" width=\"20%\" loading=\"lazy\">"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
