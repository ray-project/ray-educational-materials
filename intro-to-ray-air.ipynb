{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Ray AI Runtime (AIR)\n",
    "---\n",
    "(*Suggested Time to Complete: 30 minutes*)\n",
    "\n",
    "‚ú® Welcome to Part II of \"Introduction to Ray\"! ü™©\n",
    "\n",
    "![Map of Ray](images/map.png)\n",
    "\n",
    "*Figure 1*\n",
    "\n",
    "Ray AI Runtime (AIR) is a unified set of libraries built on top of Ray for distributed data processing, model training, tuning, model serving, and reinforcement learning, all in Python. AIR provides simple scalable machine learning for individual workloads and end-to-end workflows, bringing together an ever-growing ecosystem of integrations with your favorite machine learning frameworks.\n",
    "\n",
    "Before we lay out each library and their unique jobs to be done, let's take a moment to motivate Ray AIR by taking a high-level view of the typical data science and machine learning workflow. Developing a machine learning system is an iterative and often cyclical process that touches on the following stages:\n",
    "\n",
    "1. Data Collection & Feature Engineering: source, sample, and label raw data; preprocess raw data into well-defined input dataset(s)\n",
    "2. Model Training: the learning part of machine learning that could utilize a popular framework like PyTorch, XGBoost, or Tensorflow\n",
    "3. Hyperparameter Tuning: improve upon your baseline model by searching a hyperparameter space\n",
    "3. Model Evaluation: perform batch inference on new data to evaluate perforamnce, potentially triggering more feature engineering or finding a more relevant set of data\n",
    "4. Deployment: deploy your solution to production and/or serve your model to the end user\n",
    "\n",
    "Each of the five native libraries that Ray AIR wraps tackles a piece of the ML specific tasks outlined above that you can see illustrated in *Figure 2*. Because this abstraction layer is built on top of Ray Core, it is distributed by nature.\n",
    "\n",
    "1. üìä [Ray Data](https://docs.ray.io/en/latest/data/dataset.html): scalable, framework-agnostic loading and transforming raw data across training and prediction\n",
    "2. üöÇ [Ray Train](https://docs.ray.io/en/latest/train/train.html): distributed multi-node model training with fault tolerance that integrates with your favorite training libraries\n",
    "3. üìà [Ray Tune](https://docs.ray.io/en/latest/tune/index.html): scales experiment execution and hyperparameter tuning to optimize model performance\n",
    "4. üç¶ [Ray Serve](https://docs.ray.io/en/latest/serve/index.html): deploys your model for online inference, with optional microbatching to improve performance\n",
    "5. ü¶æ [Ray RLlib](https://docs.ray.io/en/latest/rllib/index.html): distributed reinforcement learning workloads that integrate with the other Ray AIR libraries above\n",
    "\n",
    "In this module, we will contextualize Ray Data, Train, Tune, and Serve with a common ML pipeline and discuss how each library facilitates the distinct steps we need to distribute an end-to-end example. Then, we will look at scaling individual workloads with a reinforcement learning specific application for RLlib.\n",
    "\n",
    "**Learning Objectives**\n",
    "1. Introduce the high-level data science libraries that compose Ray AIR: Data, Train, Tune, Serve, and RLlib\n",
    "2. Understand how to use Ray AIR as a unified toolkit to write an end-to-end ML application in Python as well as scale individual jobs\n",
    "3. Practice key concepts from each stage of the ML pipeline\n",
    "    - Data - use out-of-the-box `Preprocessor`s to load and transform data\n",
    "    - Train - use AIR `Trainer`s for supported ML frameworks\n",
    "    - Tune - use AIR `Tuner`s for hyperparameter search\n",
    "    - BatchPredictor - use AIR `BatchPredictor` to load model from best checkpoint for batch inference\n",
    "    - Serve - use `PredictorDeployment` for online inference\n",
    "    - RLlib - distribute RL workloads with RLlib\n",
    "\n",
    "**Prerequisites**\n",
    "- [Introduction to Ray Notebook](https://github.com): introduces Ray as a low-level distributed computing framework and covers key elements of Ray Core\n",
    "\n",
    "![End to End](images/e2e_air.png)\n",
    "\n",
    "*Figure 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Big Tips w/ NYC Taxi Data\n",
    "***\n",
    "\n",
    "To illustrate Ray AIR's capabilities, we will walk through an end-to-end example, building a simple machine learning pipeline using Ray Data, Train, Tune, and Serve. Each section will introduce key components, integrations, and typical workloads for the AIR library before demonstrating its functionality with our example application: predicting big tips on yellow taxi cabs in New York City.\n",
    "\n",
    "Suppose we want to build an application for taxi drivers in NYC that predicts if a given ride will result in a large tip (<20%). This has the potential to influence drivers' decisions when accepting jobs to maximize their margin, and conversations around [information accessbility for gig workers](https://www.nytimes.com/2022/10/11/technology/gig-workers-drivers-para-app.html) are making waves in the news. For this project, let's use the [New York City Taxi & Limousine Commission's Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) to build a binary classification model. Starting off, let's take the yellow cab data from June 2021 which contains over 2 million samples with features including `passenger_count`, `trip_distance` (in miles), `fare_amount` (including tax, tip, fees, etc.), `trip_duration` (in seconds), `hour` (hour that trip started), `day_of_week`, and our target `is_big_tip` (whether the tip amount was greater than 20%).\n",
    "\n",
    "Our workflow will consist of loading data, setting up a preprocessor, training the model with XGBoost, tuning hyperparameters, performing batch inference, and finally serving our online application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ray Data\n",
    "***\n",
    "First up, we want to load in the taxi dataset and transform its raw input into features that will be given to our machine learning model.\n",
    "\n",
    "[Ray Datasets](https://docs.ray.io/en/latest/data/user-guide.html) are the standard way to load and pass data in Ray libraries and applications. This common basis for data handling allows users to leverage different libraries from the Ray ecosystem in whatever way serves their needs without being tethered to a particular framework.\n",
    "\n",
    "The benefits of using the core `Dataset` abstractions for loading, transforming, and passing references to data in a Ray cluster include:\n",
    "\n",
    "- **Flexibility**: Compatible with a variety of file formats, data sources, and distributed frameworks, Datasets work seamlessly with library integrations like Dask on Ray and can be passed between Ray tasks and actors without copying data.\n",
    "- **Performance for ML Workloads**: Datasets offers important features like accelerator support, pipelining, and global random shuffles that accelerate ML training and inference workloads along with basic distributed data transformations such as map, filter, sort, groupby, and repartition.\n",
    "- **Persistent Preprocessor**: The `Preprocessor` primitive explicitly captures and stores the transformations applied to convert inputs into features and is applied at both training and serving to keep the processing consistent across the pipeline.\n",
    "- **Built on Ray Core**: inherits scalability to hundreds of nodes, efficient memory usage due to memory across processes on the same node, and object spilling and recovery to handle failures. Because Datasets are just lists of object references, they can be passed between tasks and actors without needing to make a copy of the data, which is crucial for making data-intensive applications and libraries scalable.\n",
    "\n",
    "In *Figure 3* below, you can see the a general pattern for creating a `Dataset`, configuring a `Preprocessor`, and passing these into the `Trainer` for consistent data handling throughout the pipeline.\n",
    "\n",
    "![Ray Data Code Snippet](images/data_code.png)\n",
    "\n",
    "*Figure 3*\n",
    "\n",
    "Let's take this generic structure and see how it plays out with our tip prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(a). Import Relevant Packages + Starting Ray\n",
    "To start, we'll import Ray (check out our [installation instructions](https://docs.ray.io/en/latest/ray-overview/installation.html)) and start a Ray cluster on our machine that can utilize all the cores available to you as workers. We use `ray.is_initialized` to ensure that we only have one Ray cluster active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 13:58:13,351\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.6</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8266\" target=\"_blank\">http://127.0.0.1:8266</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8266', python_version='3.10.6', ray_version='2.0.0', ray_commit='cba26cc83f6b5b8a2ff166594a65cb74c0ec8740', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-10-24_13-58-11_283960_35643/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-10-24_13-58-11_283960_35643/sockets/raylet', 'webui_url': '127.0.0.1:8266', 'session_dir': '/tmp/ray/session_2022-10-24_13-58-11_283960_35643', 'metrics_export_port': 64081, 'gcs_address': '127.0.0.1:62616', 'address': '127.0.0.1:62616', 'dashboard_agent_listen_port': 52365, 'node_id': 'a31940c751ab40dd69b8a31e21d443c3ecd0250ef36a03a3da923acf'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(b). Create Ray Dataset\n",
    "Here, we read in the data from an S3 `.parquet` datasource, a column-major format designed to support fast data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 14:02:45,863\tWARNING read_api.py:291 -- ‚ö†Ô∏è  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n",
      "Read progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.19s/it]\n",
      "Repartition: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 136.22it/s]\n",
      "Repartition: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 427.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(num_blocks=100, num_rows=811472, schema={passenger_count: double, trip_distance: double, fare_amount: double, trip_duration: int64, hour: int64, day_of_week: int64, is_big_tip: bool, __index_level_0__: int64})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ray.data.read_parquet(\"s3://anyscale-training-data/intro-to-ray-air/nyc_taxi_2021.parquet\")\n",
    "\n",
    "# split data into training and validation subsets\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# split datasets into blocks for parallel preprocessing\n",
    "train_dataset.repartition(100)\n",
    "valid_dataset.repartition(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üíª Coding Excercise üíª**\n",
    "\n",
    "There exist many [`Dataset` API elements](https://docs.ray.io/en/latest/data/api/dataset.html#) available for common transformations and operations. Using the above as a reference:\n",
    "1. Inspect the schema from the underlying Parquet metadata.\n",
    "2. Count how many rows are in the training and validation datasets.\n",
    "3. Inspect the first five samples of either dataset.\n",
    "4. What is the average `fare_amount` grouped by `passenger_count`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c). Preprocessing\n",
    "To transform our raw data -> features, we'll define a `Preprocessor`. What's nice about a Ray AIR `Preprocessor` is that it is automatically incorporated...\n",
    "\n",
    "- **During Training**: `Preprocessor` is passed into a `Trainer` to `fit` and `transform` input `Dataset`s.\n",
    "- **During Tuning**: each `Trial` will instantiate its own copy of the `Preprocessor` and the fitting and transformation logic will occur once per `Trial`\n",
    "- **During Checkpointing**: the `Preprocessor` is saved in the `Checkpoint` if was passed into the `Trainer`\n",
    "- **During Predicting**: if the `Checkpoint` contains a `Preprocessor`, then it will be used to call `transform_batch` on input batches prior to performing inference\n",
    "\n",
    "In the code below, we define a `MinMaxScaler` preprocessor that will scale the `trip_distance` and `trip_duration` columns by their range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import MinMaxScaler\n",
    "\n",
    "# create a preprocessor to scale some columns\n",
    "preprocessor = MinMaxScaler(columns=[\"trip_distance\", \"trip_duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üíª Coding Excercise üíª**\n",
    "\n",
    "Ray AIR provides several [preprocessors out of the box](https://docs.ray.io/en/latest/ray-air/preprocessors.html#) as well as support for implementing custom preprocessors. \n",
    "\n",
    "For this excercise, visualize the distribution for each of the features in our dataset, read through the \"Which preprocessor should you use?\" section of the linked user guide above, and determine whether `MinMaxScaler` applied to `trip_distance` and `trip_duration` is sufficient.\n",
    "\n",
    "Later on, you can compare model performance between the given preprocessor and your custom configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts in This Section**\n",
    "\n",
    "`Dataset`: The standard way to load and exchange data in Ray AIR. In AIR, Datasets are used extensively for data loading, preprocessing, and batch inference.\n",
    "\n",
    "`Preprocessors`: Preprocessors are primitives that can be used to transform input data into features. Preprocessors operate on Datasets, which makes them scalable and compatible with a variety of datasources and dataframe libraries. A Preprocessor is fitted during Training, and applied at runtime in both Training and Serving on data batches in the same way. AIR comes with a collection of built-in preprocessors, and you can also define your own with simple templates which you can read more about in our [User Guide](https://docs.ray.io/en/latest/ray-air/preprocessors.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ray Train\n",
    "***\n",
    "Following data preprocessing, we can move forward with defining our model for binary classification of big tip rides.\n",
    "\n",
    "[Ray Train](https://docs.ray.io/en/latest/ray-air/trainer.html) is a library for distributed training on Ray. It offers key tools for different parts of the training workflow, from feature processing, to scalable training, to integrations with ML tracking tools, to export mechanisms for models.\n",
    "\n",
    "Ray AIR `Trainer`s enable users to distribute training with popular machine learning frameworks like PyTorch, Tensorflow, XGBoost, HuggingFace Transformers, Scikit-Learn, and more. Train supports features like callbacks for early stopping, checkpointing, and integration with Tensorboard, Weights/Biases, and MLflow for observability.\n",
    "\n",
    "ML pracitioners tend to run into a few common problems with training models that prompt them to consider distributed solutions:\n",
    "\n",
    "1. training time is too long to be practical\n",
    "2. the data is too large to fit on one machine\n",
    "3. the model itself is too large to fit on a single machine\n",
    "\n",
    "Ray Train tackles the first problem by running distributed multi-node training with fault tolerance, leveraging Ray Data to scale preprocessing and distributed data ingestion. It is also composable with Ray Tune for scaling hyperparameter tuning and outputs the trained model in the form of a `Checkpoint` for batch inference.\n",
    "\n",
    "In *Figure 4* below, you see that training comes in two major parts: defining the `Trainer` object and then fitting it to the training dataset. In this code snippet, we use a `TorchTrainer`, however, this may be swapped out with any [integrations](https://docs.ray.io/en/latest/ray-air/package-ref.html#trainer-and-predictor-integrations).\n",
    "\n",
    "![Ray Train Code Snippet](images/train_code.png)\n",
    "\n",
    "*Figure 4*\n",
    "\n",
    "Let's put these concepts in practice by applying it to our taxi problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a). Define AIR `Trainer`\n",
    "\n",
    "There are three broad categories of Trainers that AIR offers:\n",
    "\n",
    "- Deep Learning Trainers (Pytorch, Tensorflow, Horovod)\n",
    "- Tree-based Trainers (XGBoost, LightGBM)\n",
    "- Other ML frameworks (HuggingFace, Scikit-Learn, RLlib)\n",
    "\n",
    "In the example below, we will use an `XGBoostTrainer`to perform binary classification on these NYC Taxi rides. To construct a `Trainer`, you provide:\n",
    "\n",
    "- a `ScalingConfig` which specifies how many parallel training workers and what type of resources (CPUs/GPUs) to use per worker during training.\n",
    "- a collection of datasets and a preprocessor for the provided datasets which configures preprocessing and the datasets to ingest from\n",
    "\n",
    "Optionally, you can choose to add `resume_from_checkpoint` which is a checkpoint path to resume from, should your training run be interrupted.\n",
    "\n",
    "Below, we'll set up an `XGBoostTrainer` for our classification task. [XGBoost](https://xgboost.readthedocs.io/en/stable/) is a gradient boosted decision trees library. We'll then supply our `Preprocessor` from the previous step as well as training and validation datasets to ingest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "\n",
    "    label_column=\"is_big_tip\",\n",
    "    num_boost_round=100,\n",
    "\n",
    "    scaling_config=ScalingConfig(\n",
    "        # number of workers to use\n",
    "        num_workers=8,\n",
    "        # whether to use GPU acceleration\n",
    "        use_gpu=False),\n",
    "\n",
    "    # XGBoost specific params\n",
    "    params={\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "        \"tree_method\": \"approx\"\n",
    "    },\n",
    "\n",
    "    # feed in our datasets and preprocessor\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    "    preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b). Fit the Trainer\n",
    "\n",
    "To invoke training, call `.fit()`. Trainer objects produce a `Result` object which gives you access to metrics, checkpoints, and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmy/miniforge3/lib/python3.10/site-packages/ray/train/base_trainer.py:343: UserWarning: Executing `.fit()` may leave less than 20% of CPUs in this cluster for Dataset execution, which can lead to resource contention or hangs. To avoid this, reserve at least 20% of node CPUs for Dataset execution by setting `_max_cpu_fraction_per_node = 0.8` in the Trainer scaling_config. See https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune for more info.\n",
      "  tuner = Tuner(trainable=trainable, run_config=self.run_config)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-10-24 14:55:49 (running for 00:00:19.22)<br>Memory usage on this node: 17.4/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/10 CPUs, 0/0 GPUs, 0.0/12.74 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/emmy/ray_results/XGBoostTrainer_2022-10-24_14-55-30<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th><th style=\"text-align: right;\">  valid-logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_93eb7_00000</td><td>TERMINATED</td><td>127.0.0.1:59394</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         17.1879</td><td style=\"text-align: right;\">        0.65472</td><td style=\"text-align: right;\">     0.384835</td><td style=\"text-align: right;\">         0.6583</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=59424)\u001b[0m [14:55:37] task [xgboost.ray]:5107570080 got new rank 4\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=59422)\u001b[0m [14:55:37] task [xgboost.ray]:4827600144 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=59425)\u001b[0m [14:55:37] task [xgboost.ray]:6212768992 got new rank 5\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=59426)\u001b[0m [14:55:37] task [xgboost.ray]:4978840848 got new rank 7\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=59423)\u001b[0m [14:55:37] task [xgboost.ray]:5101278576 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=59427)\u001b[0m [14:55:37] task [xgboost.ray]:5121037776 got new rank 6\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=59421)\u001b[0m [14:55:37] task [xgboost.ray]:5089744288 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=59420)\u001b[0m [14:55:37] task [xgboost.ray]:4829697392 got new rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for XGBoostTrainer_93eb7_00000:\n",
      "  date: 2022-10-24_14-55-38\n",
      "  done: false\n",
      "  experiment_id: f3ba88f2e8e34662be0f27851fc2a8e2\n",
      "  hostname: Emmys-MacBook-Pro-16\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 59394\n",
      "  time_since_restore: 6.065418004989624\n",
      "  time_this_iter_s: 6.065418004989624\n",
      "  time_total_s: 6.065418004989624\n",
      "  timestamp: 1666648538\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.39317630990903824\n",
      "  train-logloss: 0.677846201610758\n",
      "  training_iteration: 1\n",
      "  trial_id: 93eb7_00000\n",
      "  valid-error: 0.3921651024311375\n",
      "  valid-logloss: 0.6778842082323272\n",
      "  warmup_time: 0.002521038055419922\n",
      "  \n",
      "Result for XGBoostTrainer_93eb7_00000:\n",
      "  date: 2022-10-24_14-55-44\n",
      "  done: false\n",
      "  experiment_id: f3ba88f2e8e34662be0f27851fc2a8e2\n",
      "  hostname: Emmys-MacBook-Pro-16\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 59394\n",
      "  time_since_restore: 11.403082132339478\n",
      "  time_this_iter_s: 1.0101821422576904\n",
      "  time_total_s: 11.403082132339478\n",
      "  timestamp: 1666648544\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.387257959484175\n",
      "  train-logloss: 0.6565917125959274\n",
      "  training_iteration: 44\n",
      "  trial_id: 93eb7_00000\n",
      "  valid-error: 0.388526036634659\n",
      "  valid-logloss: 0.6584718954256058\n",
      "  warmup_time: 0.002521038055419922\n",
      "  \n",
      "Result for XGBoostTrainer_93eb7_00000:\n",
      "  date: 2022-10-24_14-55-49\n",
      "  done: false\n",
      "  experiment_id: f3ba88f2e8e34662be0f27851fc2a8e2\n",
      "  hostname: Emmys-MacBook-Pro-16\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 59394\n",
      "  time_since_restore: 16.730754852294922\n",
      "  time_this_iter_s: 1.0124049186706543\n",
      "  time_total_s: 16.730754852294922\n",
      "  timestamp: 1666648549\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.3850952212198689\n",
      "  train-logloss: 0.6549435264426589\n",
      "  training_iteration: 91\n",
      "  trial_id: 93eb7_00000\n",
      "  valid-error: 0.3881859139933356\n",
      "  valid-logloss: 0.6582644863235128\n",
      "  warmup_time: 0.002521038055419922\n",
      "  \n",
      "Result for XGBoostTrainer_93eb7_00000:\n",
      "  date: 2022-10-24_14-55-49\n",
      "  done: true\n",
      "  experiment_id: f3ba88f2e8e34662be0f27851fc2a8e2\n",
      "  experiment_tag: '0'\n",
      "  hostname: Emmys-MacBook-Pro-16\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 59394\n",
      "  time_since_restore: 17.187883138656616\n",
      "  time_this_iter_s: 0.41733217239379883\n",
      "  time_total_s: 17.187883138656616\n",
      "  timestamp: 1666648549\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.3848353757434248\n",
      "  train-logloss: 0.6547197552013935\n",
      "  training_iteration: 101\n",
      "  trial_id: 93eb7_00000\n",
      "  valid-error: 0.38821795453201097\n",
      "  valid-logloss: 0.6582995377268028\n",
      "  warmup_time: 0.002521038055419922\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 14:55:50,089\tINFO tune.py:758 -- Total run time: 19.33 seconds (19.22 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üíª Coding Excercise üíª**\n",
    "\n",
    "You can check out the training results from the `Result` object with the following calls:\n",
    "\n",
    "```python\n",
    "# returns last saved checkpoing\n",
    "result.checkpoint\n",
    "\n",
    "# returns the n best saved checkpoints as configured in `RunConfig.CheckpointConfig`\n",
    "result.best_checkpoints\n",
    "\n",
    "# returns the final metrics as reported\n",
    "result.metrics\n",
    "\n",
    "# returns the contain an Exception if training failed\n",
    "result.error\n",
    "```\n",
    "\n",
    "Inspect your training result below. What is the reported accuracy for the training and validation runs? Note: `error` is the binary classification error rate in this case calculated as `#(wrong cases)/#(all cases)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts in This Section**\n",
    "\n",
    "`Trainer`: Trainers are wrapper classes around third-party training frameworks such as XGBoost, Pytorch, and Tensorflow. They are built to help integrate with core Ray Actors (for distribution), Ray Tune, and Ray Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ray Tune\n",
    "***\n",
    "Ray Tune is a Python library for fast hyperparameter tuning at scale. Easily distribute your trial runs to quickly find the best hyperparameters.\n",
    "\n",
    "**Key Concept**\n",
    "\n",
    "`Tuner`: Tuners offer scalable hyperparameter tuning as part of Ray Tune. Tuners can work seamlessly with any Trainer but also can support arbitrary training functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use AIR `Tuner` for Hyperparameter Search\n",
    "What if you want to do hyperparameter optimization during training and use the best config for the model? Well, you can then use Tuner and supply your training function, `Trainer`, as part of the argument, along with other Tuner configuration.\n",
    "\n",
    "1. define the hyperparameter space\n",
    "2. define `TuneConfig` for number of trials and parallelism\n",
    "3. invoke `tuner.fit()`\n",
    "\n",
    "![Ray Tune Code Snippet](images/tune_code.png)\n",
    "\n",
    "*Figure 5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "param_space = {\"params\": {\"max_depth\": tune.randint(1, 9)}}\n",
    "metric = \"train-logloss\"\n",
    "our_mode=\"min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.tuner import Tuner, TuneConfig\n",
    "from ray.air.config import RunConfig\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space=param_space,\n",
    "    tune_config=TuneConfig(num_samples=5, metric=metric, mode=our_mode),\n",
    ")\n",
    "# Execute tuning.\n",
    "result_grid = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ray AIR Checkpoints\n",
    "***\n",
    "The AIR trainers, tuners, and custom pretrained models generate Checkpoints. An AIR Checkpoint is a format for models that are used across different components of the Ray AI Runtime. This common format allows easy interoperability among AIR components and seamless integration with external supported machine learning frameworks.\n",
    "\n",
    "Lost progress during long-running training jobs due to machine failure. The solution is to store the full state of the model periodically, so that partially trained models are available and can be used to resume training from an intermediate point, instead of starting from scratch.\n",
    "\n",
    "**Key Concept**\n",
    "\n",
    "`Checkpoints`: The AIR trainers, tuners, and custom pretrained model generate a framework-specific Checkpoint object. Checkpoints are a common interface for models that are used across different AIR components and libraries.\n",
    "\n",
    "`BatchPredictor`: loads the best model from a checkpoint to perform batch inference\n",
    "\n",
    "![Batch Predictor Code Snippet](images/batchpredict_code.png)\n",
    "\n",
    "*Figure 6*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use AIR `BatchPredictor` for Batch Prediction\n",
    "Once you have trained and tuned your model, create a batch prdictor from best model using the `best_result.checkpoint` and do batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.xgboost import XGBoostPredictor\n",
    "\n",
    "# I need a best_result\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(result.checkpoint, XGBoostPredictor)\n",
    "\n",
    "test_dataset = ray.data.read_parquet(\"data/nyc_taxi_2022.parquet\").drop(\"is_big_tip\")\n",
    "\n",
    "predicted_probabilities = batch_predictor.predict(test_dataset)\n",
    "print(\"PREDICTED PROBABILITIES\")\n",
    "predicted_probabilities.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ray Serve\n",
    "***\n",
    "Ray Serve lets you serve machine learning models in real-time or batch using a simple Python API. Serve individual models or create composite model pipelines, where you can independently deploy, update, and scale individual components.\n",
    "\n",
    "**Key Concept**\n",
    "\n",
    "`Deployments`: Deploy the model as an inference service by using Ray Serve and the `PredictorDeployment` class.\n",
    "\n",
    "![Ray Serve Code Snippet](images/serve_code.png)\n",
    "\n",
    "*Figure 7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `PredictorDeployment` for Online Inference\n",
    "Deploy the best model as an inference service by using Ray Serve and the `PredictorDeployment` class. After deploying the service, you can send requests to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "from fastapi import Request\n",
    "from ray.serve import PredictorDeployment\n",
    "from ray.serve.http_adapters import pandas_read_json\n",
    "\n",
    "serve.run(\n",
    "    PredictorDeployment.options(name=\"XGBoostService\", num_replicas=2, route_prefix=\"/rayair\").bind(\n",
    "        XGBoostPredictor, result.checkpoint, http_adapter=pandas_read_json\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "sample_input = test_dataset.take(1)\n",
    "sample_input = dict(sample_input[0])\n",
    "\n",
    "output = requests.post(\"http://localhost:8000/rayair\", json=[sample_input]).json()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "You've now just created a Ray Dataset, preprocessed some features, built a model with XGBoost, searched a hyperparameter space for the best configuration, loaded the best model from a checkpoint to perform batch inference, and served that model for online inference. Through this end-to-end example, you explored how to use Ray AIR to distribute an entire ML pipeline.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- `Datasets`\n",
    "- `Preprocessors`\n",
    "- `Trainers`\n",
    "- `Tuner`\n",
    "- `Checkpoints`\n",
    "- `BatchPredictor`\n",
    "- `Deployments`\n",
    "\n",
    "### Next Up\n",
    "\n",
    "Now that you've seen how you can use Ray AIR's unified toolkit to scale an end-to-end machine learning application, let's see how we can use it to scale individual workloads. In the next section we will cover a reinforcement learning example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning on Ray AIR\n",
    "In this example, we're going to train a reinforcement learning agent using online training. Online training means that the data from the environment is sampled while we are running the algorithm. In contrast, offline training uses data that has been stored on disk before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray RLLib\n",
    "Designed for quick interation and a fast path to production, it includes 25+ latest algorithms that are all implemented to run at scale and in multi-agent mode.\n",
    "\n",
    "RLlib is an open-source library for reinforcement learning (RL), offering support for production-level, highly distributed RL workloads while maintaining unified and simple APIs for a large variety of industry applications. Whether you would like to train your agents in a multi-agent setup, purely from offline (historic) datasets, or using externally connected simulators, RLlib offers a simple solution for each of your decision making needs.\n",
    "\n",
    "If you either have your problem coded (in Python) as an RL environment or own lots of pre-recorded, historical behavioral data to learn from, you will be up and running in only a few days. RLlib is already used in production by industry leaders in many different verticals such as climate control, industrial control, manufacturing an dlogistics, finance, gaming, automobile, robotics, boat design, and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by running some imports. We're using OpenAI's gym, which is a standard API for reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import RunConfig\n",
    "from ray.air import ScalingConfig\n",
    "from ray.air import Checkpoint\n",
    "\n",
    "from ray.train.rl import RLTrainer\n",
    "from ray.train.rl import RLPredictor\n",
    "\n",
    "from ray.air import Result\n",
    "\n",
    "from ray.tune import Tuner\n",
    "\n",
    "from ray.rllib.algorithms.marwil import BCTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the CartPole environment. insert a gif of cartpole as well as description of the premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up an RL Trainer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RLTrainer(\n",
    "    run_config = RunConfig(stop={\"training_iteration\": 5}),\n",
    "    scaling_config = ScalingConfig(num_workers=2, use_gpu=False),\n",
    "    algorithm=\"PPO\",\n",
    "    config={\n",
    "        \"env\": \"CartPole-v1\",\n",
    "        \"framework\": \"tf\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rl_ppo_online(num_workers: int, use_gpu: bool = False) -> Result:\n",
    "    print(\"Starting online training\")\n",
    "    trainer = RLTrainer(\n",
    "        run_config=RunConfig(stop={\"training_iteration\": 5}),\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "        algorithm=\"PPO\",\n",
    "        config={\n",
    "            \"env\": \"CartPole-v1\",\n",
    "            \"framework\": \"tf\",\n",
    "        },\n",
    "    )\n",
    "    # Todo (krfricke/xwjiang): Enable checkpoint config in RunConfig\n",
    "    # result = trainer.fit()\n",
    "    tuner = Tuner(\n",
    "        trainer,\n",
    "        _tuner_kwargs={\"checkpoint_at_end\": True},\n",
    "    )\n",
    "    result = tuner.fit()[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_using_checkpoint(checkpoint: Checkpoint, num_episodes) -> list:\n",
    "    predictor = RLPredictor.from_checkpoint(checkpoint)\n",
    "\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        reward = 0.0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = predictor.predict(np.array([obs]))\n",
    "            obs, r, done, _ = env.step(action[0])\n",
    "            reward += r\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train_rl_ppo_online(num_workers=2, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval_episodes = 3\n",
    "\n",
    "rewards = evaluate_using_checkpoint(result.checkpoint, num_episodes=num_eval_episodes)\n",
    "print(f\"Average reward over {num_eval_episodes} episodes: \" f\"{np.mean(rewards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Resources\n",
    "---\n",
    "If you would like to practice your new skills further with some in-depth examples beyond the embedded coding excercises, take a look at this list of suggested problems:\n",
    "- Watch the Ray Summit Talk on [Introduction to Ray AIR](https://github.com/ray-project/hackathon5-algo)\n",
    "- Check out the [Ray AIR Documentation](https://docs.ray.io/en/latest/ray-air/getting-started.html)\n",
    "- Understand its [Components and APIs](https://docs.ray.io/en/latest/ray-air/package-ref.html)\n",
    "- Ray AIR [User Guides](https://docs.ray.io/en/latest/ray-air/user-guides.html) and [Examples](https://docs.ray.io/en/latest/ray-air/examples/index.html)\n",
    "\n",
    "\n",
    "# Next Steps\n",
    "---\n",
    "üéâ Congratulations! You have completed the tutorial on an Introduction to Ray AI Runtime! We dicussed each library in Ray AIR (Data, Train, Tune, Serve, RLLib) and saw some example machine learning workloads to be done with each. In the next module, we will introduce the ecosystem of integrated libraries runs on Ray Core's distributed execution engine, and with Ray Clusters, you can deploy your workloads on AWS, GCP, Azure, or on Kubernetes.\n",
    "\n",
    "From here, you can learn and get more involved with our active community of developers and researchers by checking out the following resources:\n",
    "- üíª [Official Ray Website](https://www.ray.io/): Browse the ecosystem and use this site as a hub to get the information that you need to get going and building with Ray.\n",
    "- üí¨ [Join the Community on Slack](https://forms.gle/9TSdDYUgxYs8SA9e8): Find friends to discuss your new learnings in our Slack space.\n",
    "- üì£ [Use the Discussion Board](https://discuss.ray.io/): Ask questions, follow topics, and view announcements on this community forum.\n",
    "- üôã‚Äç‚ôÄÔ∏è [Join a Meetup Group](https://www.meetup.com/Bay-Area-Ray-Meetup/): Tune in on meet-ups to listen to compelling talks, get to know other users, and meet the team behind Ray.\n",
    "- ü™≤ [Open an Issue](https://github.com/ray-project/ray/issues/new/choose): Ray is constantly evolving to improve developer experience. Submit feature requests, bug-reports, and get help via GitHub issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "567405a8058597909526349386224fe35dd047505a91307e44ed44be00113429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
