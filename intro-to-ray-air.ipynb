{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Ray AI Runtime (AIR)\n",
    "---\n",
    "(*Suggested Time to Complete: 30 minutes*)\n",
    "\n",
    "![Ray AIR](images/Ray_AIR.png)\n",
    "*Figure 1*\n",
    "\n",
    "Ray AI Runtime (AIR) is a unified set of libraries built on top of Ray for distributed data processing, model training, tuning, model serving, and reinforcement learning, all in Python. AIR provides simple scalable machine learning for individual workloads and end-to-end workflows, bringing together an ecosystem of integrations.\n",
    "\n",
    "Before we lay out each library and their unique jobs to be done, let's take a moment to motivate Ray AIR by taking a high-level view of the data science and machine learning workflow.\n",
    "\n",
    "Developing a machine learning system is an iterative and often cyclical process that roughly touches on the following stages:\n",
    "\n",
    "1. Business Needs: work with stakeholders to identify business requirements and align on which metric to optimize\n",
    "2. Data Collection: source and collect data and labels\n",
    "3. Feature Engineering: turn raw data into usable material\n",
    "4. Model Training: the learning part of machine learning\n",
    "5. Model Evaluation: try to improve upon your baseline model with hyperparameter tuning or more feature engineering or even a more relevant set of data\n",
    "6. Deployment: deploy your solution to production and/or serve your model to the end user\n",
    "\n",
    "Each of the five main native libraries that Ray AIR wraps tackles a specific piece of the ML specific tasks outlined above, and because this abstraction layer is built on top of Ray Core, it is distributed by nature.\n",
    "\n",
    "1. [Ray Data](https://docs.ray.io/en/latest/data/dataset.html): load and manipulate data\n",
    "2. [Ray Train](https://docs.ray.io/en/latest/train/train.html): scales model training for popular ML frameworks\n",
    "3. [Ray Tune](https://docs.ray.io/en/latest/tune/index.html): scales experiment execution and hyperparameter tuning\n",
    "4. [Ray Serve](https://docs.ray.io/en/latest/serve/index.html): scales model serving\n",
    "5. [Ray RLlib](https://docs.ray.io/en/latest/rllib/index.html): for distributed reinforment learning workloads\n",
    "\n",
    "Let's contextualize Ray Data, Train, Tune, and Serve with a common ML pipeline and discuss how each library intersects with the distinct steps we need to distribute this end-to-end example. Towards the end, we will examine a reinforment learning specific workload for RLlib.\n",
    "\n",
    "**Learning Objectives**\n",
    "1. Understand the high-level data science libraries that compose Ray AIR: Data, Train, Tune, Serve, and RLlib\n",
    "2. Understand how to use Ray AIR as a unified toolkit to write an end-to-end ML application in Python\n",
    "3. Practice key concepts from each stage of the ML pipeline\n",
    "    - Data - use out-of-the-box preprocessors\n",
    "    - Train - use AIR Trainers for supported ML frameworks\n",
    "    - Tune - use AIR Tuners for hyperparameter search\n",
    "    - BatchPredictor - use AIR `BatchPredictor` to load model from best checkpoint for batch inference\n",
    "    - Serve - use `PredictorDeployment` for online inference\n",
    "    - RLlib - distribute RL workloads with RLlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Example: Breast Cancer Biopsy Classification\n",
    "***\n",
    "To illustrate Ray AIR's capabilities, we will walk through a practical, end-to-end example of building a typical machine learning pipeline using Ray Data, Train, Tune, and Serve. We will build a binary classification model based off the [Wisconsin Breast Cancer Dataset](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)) which contains 569 samples of malignant and benign biopsies. Our workflow will start by loading data, performing some basic preprocessing, train the model with XGBoost, tune hyperparameters, perform batch inference, and then finally deploy our application online.\n",
    "\n",
    "<!-- As we encounter each stage, we will formally introduce the Ray library that does the heavy lifting. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Data\n",
    "***\n",
    "First up, we want to load in the breast cancer dataset into a format compatible across AIR. Ray Datasets are the standard way to load and exchange data in Ray libraries and applications. They provide basic distributed data transformations such as map, filter, and repartition, and are compatible with a variety of file formats, data sources, and distributed frameworks.\n",
    "\n",
    "**Key Concepts**\n",
    "\n",
    "`Dataset`: Ray Datasets are the standard way to load and exchange data in Ray AIR. In AIR, Datasets are used extensively for data loading, preprocessing, and batch inference.\n",
    "\n",
    "`Preprocessors`: Preprocessors are primitives that can be used to transform input data into features. Preprocessors operate on Datasets, which makes them scalable and compatible with a variety of datasources and dataframe libraries. A Preprocessor is fitted during Training, and applied at runtime in both Training and Serving on data batches in the same way. AIR comes with a collection of built-in preprocessors, and you can also define your own with simple templates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Packages + Starting Ray\n",
    "To start, we'll import Ray (check out our [installation instructions](https://docs.ray.io/en/latest/ray-overview/installation.html)) and start a Ray cluster on our machine that can utilize all the cores available to you as workers. We use `ray.is_initialized` to ensure that we only have one Ray cluster active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os, random, warnings\n",
    "import pandas as pd\n",
    "import ray\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init(logging_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Ray Dataset\n",
    "Here, we read in the data from an S3 `.csv` datasource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ray.data.read_csv(\"s3://anonymous@air-example-data/breast_cancer.csv\")\n",
    "\n",
    "# split data into train and validation.\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "test_dataset = valid_dataset.drop_columns([\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "We define a `Preprocessor` pipeline for our task. It's automatically used in the training function to `fit` and `transform` your datasets for training and validation. you don't have to explicitly call the preprocess before training or interence. Ray AIR toolkit automatically does that for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import StandardScaler\n",
    "\n",
    "# create a preprocessor to scale some columns\n",
    "preprocessor = StandardScaler(columns=[\"mean radius\", \"mean texture\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Train\n",
    "***\n",
    "Ray Train is a lightweight library for distributed deep learning that allows you to easily supercharge your distributed PyTorch and TensorFlow training on Ray.\n",
    "\n",
    "**Trainer**: Trainers are wrapper classes around third-party training frameworks such as XGBoost and Pytoch. They are built to help integrate with core Ray actors (for distribution), Ray Tune, and Ray Datasets.\n",
    "\n",
    "**Checkpoints**: The AIR trainers, tuners, and custom pretrained model generate a framework-specific Checkpoint object. Checkpoints are a common interface for models that are used across different AIR components and libraries.\n",
    "\n",
    "**Batch Predictor**: You can take a checkpoint and do batch inference using the BatchPredictor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Tune\n",
    "***\n",
    "Ray Tune is a Python library for fast hyperparameter tuning at scale. Easily distribute your trial runs to quickly find the best hyperparameters.\n",
    "\n",
    "**Tuner**: Tuners offer scalable hyperparameter tuning as part of Ray Tune. Tuners can work seamlessly with any Trainer but also can support arbitrary training functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Serve\n",
    "***\n",
    "Ray Serve lets you serve machine learning models in real-time or batch using a simple Python API. Serve individual models or create composite model pipelines, where you can independently deploy, update, and scale individual components.\n",
    "\n",
    "**Deployments**: Deploy the model as an inference service by using Ray Serve and the `PredictorDeployment` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Key Concepts\n",
    "### Key API Elements in This Section\n",
    "### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Example\n",
    "words go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray RLLib\n",
    "RLlib is the industry-standard reinforcement learning Python framework built on Ray. Designed for quick interation and a fast path to production, it includes 25+ latest algorithms that are all implemented to run at scale and in multi-agent mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Resources\n",
    "---\n",
    "If you would like to practice your new skills further with some in-depth examples beyond the embedded coding excercises, take a look at this list of suggested problems:\n",
    "- Watch the Ray Summit Talk on [Introduction to Ray AIR](https://github.com/ray-project/hackathon5-algo)\n",
    "- Check out the [Ray AIR Documentation](https://docs.ray.io/en/latest/ray-air/getting-started.html)\n",
    "- Understand its [Components and APIs](https://docs.ray.io/en/latest/ray-air/package-ref.html)\n",
    "- Ray AIR [User Guides](https://docs.ray.io/en/latest/ray-air/user-guides.html) and [Examples](https://docs.ray.io/en/latest/ray-air/examples/index.html)\n",
    "\n",
    "\n",
    "# Next Steps\n",
    "---\n",
    "üéâ Congratulations! You have completed the tutorial on an Introduction to Ray AI Runtime! We dicussed each library in Ray AIR (Data, Train, Tune, Serve, RLLib) and saw some example machine learning workloads to be done with each. In the next module, we will introduce the ecosystem of integrated libraries runs on Ray Core's distributed execution engine, and with Ray Clusters, you can deploy your workloads on AWS, GCP, Azure, or on Kubernetes.\n",
    "\n",
    "From here, you can learn and get more involved with our active community of developers and researchers by checking out the following resources:\n",
    "- üíª [Official Ray Website](https://www.ray.io/): Browse the ecosystem and use this site as a hub to get the information that you need to get going and building with Ray.\n",
    "- üí¨ [Join the Community on Slack](https://forms.gle/9TSdDYUgxYs8SA9e8): Find friends to discuss your new learnings in our Slack space.\n",
    "- üì£ [Use the Discussion Board](https://discuss.ray.io/): Ask questions, follow topics, and view announcements on this community forum.\n",
    "- üôã‚Äç‚ôÄÔ∏è [Join a Meetup Group](https://www.meetup.com/Bay-Area-Ray-Meetup/): Tune in on meet-ups to listen to compelling talks, get to know other users, and meet the team behind Ray.\n",
    "- ü™≤ [Open an Issue](https://github.com/ray-project/ray/issues/new/choose): Ray is constantly evolving to improve developer experience. Submit feature requests, bug-reports, and get help via GitHub issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "567405a8058597909526349386224fe35dd047505a91307e44ed44be00113429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
