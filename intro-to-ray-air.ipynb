{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Ray AI Runtime (AIR)\n",
    "---\n",
    "(*Suggested Time to Complete: 30 minutes*)\n",
    "\n",
    "‚ú® Welcome to Part II of \"Introduction to Ray\"! ü™©\n",
    "\n",
    "![Map of Ray](images/map.png)\n",
    "\n",
    "*Figure 1*\n",
    "\n",
    "Ray AI Runtime (AIR) is a unified set of libraries built on top of Ray for distributed data processing, model training, tuning, model serving, and reinforcement learning, all in Python. AIR provides simple scalable machine learning for individual workloads and end-to-end workflows, bringing together an ever-growing ecosystem of integrations with your favorite machine learning frameworks.\n",
    "\n",
    "Before we lay out each library and their unique jobs to be done, let's take a moment to motivate Ray AIR by taking a high-level view of the typical data science and machine learning workflow. Developing a machine learning system is an iterative and often cyclical process that touches on the following stages:\n",
    "\n",
    "1. Data Collection & Feature Engineering: source, sample, and label raw data; preprocess raw data into well-defined input dataset(s)\n",
    "2. Model Training: the learning part of machine learning that could utilize a popular framework like PyTorch, XGBoost, or Tensorflow\n",
    "3. Hyperparameter Tuning: improve upon your baseline model by searching a hyperparameter space\n",
    "3. Model Evaluation: perform batch inference on new data to evaluate perforamnce, potentially triggering more feature engineering or finding a more relevant set of data\n",
    "4. Deployment: deploy your solution to production and/or serve your model to the end user\n",
    "\n",
    "Each of the five native libraries that Ray AIR wraps tackles a piece of the ML specific tasks outlined above that you can see illustrated in *Figure 2*. Because this abstraction layer is built on top of Ray Core, it is distributed by nature.\n",
    "\n",
    "1. üìä [Ray Data](https://docs.ray.io/en/latest/data/dataset.html): scalable, framework-agnostic loading and transforming raw data across training and prediction\n",
    "2. üöÇ [Ray Train](https://docs.ray.io/en/latest/train/train.html): distributed multi-node model training with fault tolerance that integrates with your favorite training libraries\n",
    "3. üìà [Ray Tune](https://docs.ray.io/en/latest/tune/index.html): scales experiment execution and hyperparameter tuning to optimize model performance\n",
    "4. üç¶ [Ray Serve](https://docs.ray.io/en/latest/serve/index.html): deploys your model for online inference, with optional microbatching to improve performance\n",
    "5. ü¶æ [Ray RLlib](https://docs.ray.io/en/latest/rllib/index.html): distributed reinforcement learning workloads that integrate with the other Ray AIR libraries above\n",
    "\n",
    "In this module, we will contextualize Ray Data, Train, Tune, and Serve with a common ML pipeline and discuss how each library facilitates the distinct steps we need to distribute an end-to-end example. Then, we will look at scaling individual workloads with a reinforcement learning specific application for RLlib.\n",
    "\n",
    "**Learning Objectives**\n",
    "1. Understand the high-level data science libraries that compose Ray AIR: Data, Train, Tune, Serve, and RLlib\n",
    "2. Understand how to use Ray AIR as a unified toolkit to write an individual as well as end-to-end ML application in Python\n",
    "3. Practice key concepts from each stage of the ML pipeline\n",
    "    - Data - use out-of-the-box `Preprocessor`s to load and transform data\n",
    "    - Train - use AIR `Trainer`s for supported ML frameworks\n",
    "    - Tune - use AIR `Tuner`s for hyperparameter search\n",
    "    - BatchPredictor - use AIR `BatchPredictor` to load model from best checkpoint for batch inference\n",
    "    - Serve - use `PredictorDeployment` for online inference\n",
    "    - RLlib - distribute RL workloads with RLlib\n",
    "\n",
    "**Prerequisites**\n",
    "- [Introduction to Ray Notebook](https://github.com): introduces Ray as a low-level distributed computing framework and covers key elements of Ray Core\n",
    "\n",
    "![End to End](images/e2e_air.png)\n",
    "\n",
    "*Figure 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Big Tips w/ NYC Taxi Data\n",
    "***\n",
    "\n",
    "To illustrate Ray AIR's capabilities, we will walk through an end-to-end example, building a simple machine learning pipeline using Ray Data, Train, Tune, and Serve. In each section, we will introduce each library's key concepts and how they relate to other libraries in AIR. Then, we will apply our learnings in a structured example and an open-ended excercise that relates back to the problem narrative.\n",
    "\n",
    "Suppose we ************ we want to make an application for taxi drivers so that they can try to maximize their tips, so we want to predict big tips depending on features coming in.\n",
    "\n",
    "\n",
    "To illustrate Ray AIR's capabilities, we will walk through a practical, end-to-end example of building a typical machine learning pipeline using Ray Data, Train, Tune, and Serve. We will build a binary classification model based off the [New York City Taxi Dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) which contains over 2 million records of yellow cab rides taken in the city. We're trying to train out model to predict if rides will result in a  large tip (<20%) based off of features such as the ride duration, date, time, overall fare amount, and passenger count. Our workflow will start by loading data, performing some basic preprocessing, train the model with XGBoost, tune hyperparameters, perform batch inference, and then finally deploy our application online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ray Data\n",
    "***\n",
    "First up, we want to load in the taxi dataset and transform its raw data into features that will be input to our machine learning model. Ray Datasets are the standard way to load and exchange data in Ray libraries and applications. They provide basic distributed data transformations such as map, filter, and repartition and are compatible with a variety of file formats, data sources, and distributed frameworks.\n",
    "\n",
    "**Key Concepts**\n",
    "\n",
    "`Dataset`: The standard way to load and exchange data in Ray AIR. In AIR, Datasets are used extensively for data loading, preprocessing, and batch inference.\n",
    "\n",
    "`Preprocessors`: Preprocessors are primitives that can be used to transform input data into features. Preprocessors operate on Datasets, which makes them scalable and compatible with a variety of datasources and dataframe libraries. A Preprocessor is fitted during Training, and applied at runtime in both Training and Serving on data batches in the same way. AIR comes with a collection of built-in preprocessors, and you can also define your own with simple templates which you can read more about in our [User Guide](https://docs.ray.io/en/latest/ray-air/preprocessors.html).\n",
    "\n",
    "![Ray Data Code Snippet](images/data_code.png)\n",
    "\n",
    "*Figure 3*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Packages + Starting Ray\n",
    "To start, we'll import Ray (check out our [installation instructions](https://docs.ray.io/en/latest/ray-overview/installation.html)) and start a Ray cluster on our machine that can utilize all the cores available to you as workers. We use `ray.is_initialized` to ensure that we only have one Ray cluster active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 21:19:17,442\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.6</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.10.6', ray_version='2.0.0', ray_commit='cba26cc83f6b5b8a2ff166594a65cb74c0ec8740', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-10-19_21-19-15_366947_71598/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-10-19_21-19-15_366947_71598/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-10-19_21-19-15_366947_71598', 'metrics_export_port': 63825, 'gcs_address': '127.0.0.1:63322', 'address': '127.0.0.1:63322', 'dashboard_agent_listen_port': 52365, 'node_id': '4f72d0dc53d7a2cfa9e94a1a630ddef2d7e3db7b415db00dfde7e498'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Ray Dataset\n",
    "Here, we read in the data from an S3 `.csv` datasource. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the June 2021 dataset for training and the June 2022 dataset for batch inference later\n",
    "dataset = ray.data.read_parquet(\"data/nyc_taxi_2021.parquet\")\n",
    "\n",
    "# split data into training and validation subsets\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "valid_dataset = valid_dataset.drop_columns([\"is_big_tip\"])\n",
    "\n",
    "# repartition the dataset for maximum parallelism\n",
    "train_dataset.repartition(100)\n",
    "valid_dataset.repartition(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üëæ Coding Excercise üëæ**\n",
    "\n",
    "There exist many [`Dataset` API elements](https://docs.ray.io/en/latest/data/api/dataset.html#) available for common transformations and operations. Using the above as a reference:\n",
    "1. inspect the schema\n",
    "2. visualize the first five samples\n",
    "3. evaluate whether this dataset contains extreme outliers; if so, drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "In the code below, we define a `StandardScaler` preprocessor because we wish to normalize the *approximately normal* `trip_distance` and `trip_duration` columns.\n",
    "\n",
    "What's nice about a Ray AIR `Preprocessor` is that it is automatically incorporated into an end-to-end application built with AIR.\n",
    "\n",
    "- During Training: `Preprocessor` is passed into a `Trainer` to `fit` and `transform` input `Dataset`s.\n",
    "- During Tuning: each `Trial` will isntantiate its own copy of the `Preprocessor` and the fitting and transofrmation logic will occur once per `Trial`\n",
    "- During Checkpoint: the `Preprocessor` is saved in the `Checkpoint` is if was passed into the `Trainer`\n",
    "- During Predicting: if the `Checkpoint` contains a `Preprocessor`, then it will be used to call `transform_batch` on input batches prior to performing inference\n",
    "\n",
    "This kind of heavy lifting behind the scenes is one of the major advantages of Ray AIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import StandardScaler\n",
    "\n",
    "# create a preprocessor to scale some columns\n",
    "preprocessor = StandardScaler(columns=[\"trip_distance\", \"trip_duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ray Train\n",
    "***\n",
    "Following data preprocessing, we can move forward with defining our model and fitting it on our training set. Ray Train is a lightweight library for distributed deep learning that allows you to easily supercharge your distributed training on Ray.\n",
    "\n",
    "**Key Concept**\n",
    "\n",
    "`Trainer`: Trainers are wrapper classes around third-party training frameworks such as XGBoost, Pytorch, and Tensorflow. They are built to help integrate with core Ray Actors (for distribution), Ray Tune, and Ray Datasets.\n",
    "\n",
    "![Ray Train Code Snippet](images/train_code.png)\n",
    "\n",
    "*Figure 3*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define AIR `Trainer`\n",
    "\n",
    "In Ray AIR, `Trainer`s provide a way to scale out training with popular machine learning frameworks. As part of Ray Train, `Trainer`s enable users to run distributed multi-node training with fault tolerance. Fully integrated with the Ray ecosystem, Trainers leverage Ray Data to enable scalable preprocessing and performant distributed data ingestion. Also, Trainers can be composed with `Tuner`s for distributed hyperparameter tuning. After executing training, `Trainer`s output the trained model in the form of a `Checkpoint`, which can be used for batch or online prediction inference.\n",
    "\n",
    "There are three broad categories of Trainers that AIR offers:\n",
    "\n",
    "- Deep Learning Trainers (Pytorch, Tensorflow, Horovod)\n",
    "- Tree-based Trainers (XGBoost, LightGBM)\n",
    "- Other ML frameworks (HuggingFace, Scikit-Learn, RLlib)\n",
    "\n",
    "In the example below, we will use an `XGBoostTrainer`to perform binary classification on these NYC Taxi rides. To construct a `Trainer`, you extent drom the `BaseTrainer` interface by providing:\n",
    "\n",
    "- a `scaling_config` which specifies how many parallel training workers and what type of resources (CPUs/GPUs) to use per worker during training.\n",
    "- a `run_config` which configures a variety of runtime parameters such as fault tolerance, logging, and callbacks\n",
    "- a collection of datasets and a preprocessor for the provided datasets which configures preprocessing and the datasets to ingest from\n",
    "- `resume_from_checkpoint` which is a checkpoint path to resume from, should your training run be interrupted\n",
    "\n",
    "In summary, the steps for our example are:\n",
    "\n",
    "1. define the parallelism for Ray compute\n",
    "2. define the XGBoost parameters for training\n",
    "3. supply the preprocessor for fitting and transforming dataset during training and validation\n",
    "4. provide the datasets for training and validation\n",
    "5. invoke `trainer.fit` to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    scaling_config=ScalingConfig(\n",
    "        # Number of workers to use for data parallelism.\n",
    "        num_workers=2,\n",
    "        # Whether to use GPU acceleration.\n",
    "        use_gpu=False),\n",
    "    label_column=\"is_big_tip\",\n",
    "    num_boost_round=20,\n",
    "    params={\n",
    "        # XGBoost specific params\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    },\n",
    "    # our train and validation dataset and preprocessor\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    "    preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer objects produce a Result object after calling `.fit()`. These objects contain training metrics as well as checkpoints to retrieve the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the trainer\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üëæ Coding Excercise üëæ**\n",
    "\n",
    "There exist many [`Dataset` API elements](https://docs.ray.io/en/latest/data/api/dataset.html#) available for common transformations and operations. Using the above as a reference:\n",
    "1. inspect the schema\n",
    "2. visualize the first five samples\n",
    "3. evaluate whether this dataset contains extreme outliers; if so, drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ray Tune\n",
    "***\n",
    "Ray Tune is a Python library for fast hyperparameter tuning at scale. Easily distribute your trial runs to quickly find the best hyperparameters.\n",
    "\n",
    "**Key Concept**\n",
    "\n",
    "`Tuner`: Tuners offer scalable hyperparameter tuning as part of Ray Tune. Tuners can work seamlessly with any Trainer but also can support arbitrary training functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use AIR `Tuner` for Hyperparameter Search\n",
    "What if you want to do hyperparameter optimization during training and use the best config for the model? Well, you can then use Tuner and supply your training function, `Trainer`, as part of the argument, along with other Tuner configuration.\n",
    "\n",
    "1. define the hyperparameter space\n",
    "2. define `TuneConfig` for number of trials and parallelism\n",
    "3. invoke `tuner.fit()`\n",
    "\n",
    "![Ray Tune Code Snippet](images/tune_code.png)\n",
    "\n",
    "*Figure 5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "param_space = {\"params\": {\"max_depth\": tune.randint(1, 9)}}\n",
    "metric = \"train-logloss\"\n",
    "our_mode=\"min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.tuner import Tuner, TuneConfig\n",
    "from ray.air.config import RunConfig\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space=param_space,\n",
    "    tune_config=TuneConfig(num_samples=5, metric=metric, mode=our_mode),\n",
    ")\n",
    "# Execute tuning.\n",
    "result_grid = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ray AIR Checkpoints\n",
    "***\n",
    "The AIR trainers, tuners, and custom pretrained models generate Checkpoints. An AIR Checkpoint is a format for models that are used across different components of the Ray AI Runtime. This common format allows easy interoperability among AIR components and seamless integration with external supported machine learning frameworks.\n",
    "\n",
    "**Key Concept**\n",
    "\n",
    "`Checkpoints`: The AIR trainers, tuners, and custom pretrained model generate a framework-specific Checkpoint object. Checkpoints are a common interface for models that are used across different AIR components and libraries.\n",
    "\n",
    "`BatchPredictor`: loads the best model from a checkpoint to perform batch inference\n",
    "\n",
    "![Batch Predictor Code Snippet](images/batchpredict_code.png)\n",
    "\n",
    "*Figure 6*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use AIR `BatchPredictor` for Batch Prediction\n",
    "Once you have trained and tuned your model, create a batch prdictor from best model using the `best_result.checkpoint` and do batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.xgboost import XGBoostPredictor\n",
    "\n",
    "# I need a best_result\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(best_result.checkpoint, XGBoostPredictor)\n",
    "\n",
    "test_dataset = ray.data.read_parquet(\"data/nyc_taxi_2022.parquet\").drop(\"is_big_tip\")\n",
    "\n",
    "predicted_probabilities = batch_predictor.predict(test_dataset)\n",
    "print(\"PREDICTED PROBABILITIES\")\n",
    "predicted_probabilities.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ray Serve\n",
    "***\n",
    "Ray Serve lets you serve machine learning models in real-time or batch using a simple Python API. Serve individual models or create composite model pipelines, where you can independently deploy, update, and scale individual components.\n",
    "\n",
    "**Key Concept**\n",
    "\n",
    "`Deployments`: Deploy the model as an inference service by using Ray Serve and the `PredictorDeployment` class.\n",
    "\n",
    "![Ray Serve Code Snippet](images/serve_code.png)\n",
    "\n",
    "*Figure 7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `PredictorDeployment` for Online Inference\n",
    "Deploy the best model as an inference service by using Ray Serve and the `PredictorDeployment` class. After deploying the service, you can send requests to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "from fastapi import Request\n",
    "from ray.serve import PredictorDeployment\n",
    "from ray.serve.http_adapters import pandas_read_json\n",
    "\n",
    "serve.run(\n",
    "    PredictorDeployment.options(name=\"XGBoostService\", num_replicas=2, route_prefix=\"/rayair\").bind(\n",
    "        XGBoostPredictor, result.checkpoint, http_adapter=pandas_read_json\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "sample_input = test_dataset.take(1)\n",
    "sample_input = dict(sample_input[0])\n",
    "\n",
    "output = requests.post(\"http://localhost:8000/rayair\", json=[sample_input]).json()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "You've now just created a Ray Dataset, preprocessed some features, built a model with XGBoost, searched a hyperparameter space for the best configuration, loaded the best model from a checkpoint to perform batch inference, and served that model for online inference. Through this end-to-end example, you explored how to use Ray AIR to distribute an entire ML pipeline.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- `Datasets`\n",
    "- `Preprocessors`\n",
    "- `Trainers`\n",
    "- `Tuner`\n",
    "- `Checkpoints`\n",
    "- `BatchPredictor`\n",
    "- `Deployments`\n",
    "\n",
    "### Next Up\n",
    "\n",
    "Now that you've seen how you can use Ray AIR's unified toolkit to scale an end-to-end machine learning application, let's see how we can use it to scale individual workloads. In the next section we will cover a reinforcement learning example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning on Ray AIR\n",
    "In this example, we're going to train a reinforcement learning agent using online training. Online training means that the data from the environment is sampled while we are running the algorithm. In contrast, offline training uses data that has been stored on disk before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray RLLib\n",
    "RLlib is the industry-standard reinforcement learning Python framework built on Ray. Designed for quick interation and a fast path to production, it includes 25+ latest algorithms that are all implemented to run at scale and in multi-agent mode.\n",
    "\n",
    "RLlib is an open-source library for reinforcement learning (RL), offering support for production-level, highly distributed RL workloads while maintaining unified and simple APIs for a large variety of industry applications. Whether you would like to train your agents in a multi-agent setup, purely from offline (historic) datasets, or using externally connected simulators, RLlib offers a simple solution for each of your decision making needs.\n",
    "\n",
    "If you either have your problem coded (in Python) as an RL environment or own lots of pre-recorded, historical behavioral data to learn from, you will be up and running in only a few days. RLlib is already used in production by industry leaders in many different verticals such as climate control, industrial control, manufacturing an dlogistics, finance, gaming, automobile, robotics, boat design, and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by running some imports. We're using OpenAI's gym, which is a standard API for reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import RunConfig\n",
    "from ray.air import ScalingConfig\n",
    "from ray.air import Checkpoint\n",
    "\n",
    "from ray.train.rl import RLTrainer\n",
    "from ray.train.rl import RLPredictor\n",
    "\n",
    "from ray.air import Result\n",
    "\n",
    "from ray.tune import Tuner\n",
    "\n",
    "from ray.rllib.algorithms.marwil import BCTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the CartPole environment. insert a gif of cartpole as well as description of the premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up an RL Trainer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RLTrainer(\n",
    "    run_config = RunConfig(stop={\"training_iteration\": 5}),\n",
    "    scaling_config = ScalingConfig(num_workers=2, use_gpu=False),\n",
    "    algorithm=\"PPO\",\n",
    "    config={\n",
    "        \"env\": \"CartPole-v1\",\n",
    "        \"framework\": \"tf\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rl_ppo_online(num_workers: int, use_gpu: bool = False) -> Result:\n",
    "    print(\"Starting online training\")\n",
    "    trainer = RLTrainer(\n",
    "        run_config=RunConfig(stop={\"training_iteration\": 5}),\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "        algorithm=\"PPO\",\n",
    "        config={\n",
    "            \"env\": \"CartPole-v1\",\n",
    "            \"framework\": \"tf\",\n",
    "        },\n",
    "    )\n",
    "    # Todo (krfricke/xwjiang): Enable checkpoint config in RunConfig\n",
    "    # result = trainer.fit()\n",
    "    tuner = Tuner(\n",
    "        trainer,\n",
    "        _tuner_kwargs={\"checkpoint_at_end\": True},\n",
    "    )\n",
    "    result = tuner.fit()[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_using_checkpoint(checkpoint: Checkpoint, num_episodes) -> list:\n",
    "    predictor = RLPredictor.from_checkpoint(checkpoint)\n",
    "\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        reward = 0.0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = predictor.predict(np.array([obs]))\n",
    "            obs, r, done, _ = env.step(action[0])\n",
    "            reward += r\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train_rl_ppo_online(num_workers=2, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval_episodes = 3\n",
    "\n",
    "rewards = evaluate_using_checkpoint(result.checkpoint, num_episodes=num_eval_episodes)\n",
    "print(f\"Average reward over {num_eval_episodes} episodes: \" f\"{np.mean(rewards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Resources\n",
    "---\n",
    "If you would like to practice your new skills further with some in-depth examples beyond the embedded coding excercises, take a look at this list of suggested problems:\n",
    "- Watch the Ray Summit Talk on [Introduction to Ray AIR](https://github.com/ray-project/hackathon5-algo)\n",
    "- Check out the [Ray AIR Documentation](https://docs.ray.io/en/latest/ray-air/getting-started.html)\n",
    "- Understand its [Components and APIs](https://docs.ray.io/en/latest/ray-air/package-ref.html)\n",
    "- Ray AIR [User Guides](https://docs.ray.io/en/latest/ray-air/user-guides.html) and [Examples](https://docs.ray.io/en/latest/ray-air/examples/index.html)\n",
    "\n",
    "\n",
    "# Next Steps\n",
    "---\n",
    "üéâ Congratulations! You have completed the tutorial on an Introduction to Ray AI Runtime! We dicussed each library in Ray AIR (Data, Train, Tune, Serve, RLLib) and saw some example machine learning workloads to be done with each. In the next module, we will introduce the ecosystem of integrated libraries runs on Ray Core's distributed execution engine, and with Ray Clusters, you can deploy your workloads on AWS, GCP, Azure, or on Kubernetes.\n",
    "\n",
    "From here, you can learn and get more involved with our active community of developers and researchers by checking out the following resources:\n",
    "- üíª [Official Ray Website](https://www.ray.io/): Browse the ecosystem and use this site as a hub to get the information that you need to get going and building with Ray.\n",
    "- üí¨ [Join the Community on Slack](https://forms.gle/9TSdDYUgxYs8SA9e8): Find friends to discuss your new learnings in our Slack space.\n",
    "- üì£ [Use the Discussion Board](https://discuss.ray.io/): Ask questions, follow topics, and view announcements on this community forum.\n",
    "- üôã‚Äç‚ôÄÔ∏è [Join a Meetup Group](https://www.meetup.com/Bay-Area-Ray-Meetup/): Tune in on meet-ups to listen to compelling talks, get to know other users, and meet the team behind Ray.\n",
    "- ü™≤ [Open an Issue](https://github.com/ray-project/ray/issues/new/choose): Ray is constantly evolving to improve developer experience. Submit feature requests, bug-reports, and get help via GitHub issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "567405a8058597909526349386224fe35dd047505a91307e44ed44be00113429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
