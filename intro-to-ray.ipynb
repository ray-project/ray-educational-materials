{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Ray\n",
    "---\n",
    "Welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ray Core\n",
    "Ray Core is the foundation of the entire Ray ecosystem. With simple primitives, it lets every engineer easily build scalable, distributed systems in Python in a cloud-agnostic way.\n",
    "\n",
    "### Why Ray Core?\n",
    "- Simple Primitives: flexibly compose distributed applications with tasks, actors, and objects in native Python code.\n",
    "- Multi-cloud: run the same Ray code on any cloud --AWS, GCP, Azure -- or even on-prem.\n",
    "- Dynamic Scaling: Ray Core can automatically scale (using Ray Autoscaler) up or down to smoothly handle changing compute load.\n",
    "- Massive Scalability: Ray Core can easily scale to thousands of cores, and is getting more scalable with every release.\n",
    "- Open Community / Ecosystem: With a vibrant dedicated community and rich ecosystem of integrations, fixes, and best practices are easy to find.\n",
    "- Laptop -> Cluster With Ease: With Ray Client, going from laptop to cluster is as easy as changing 1 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate pi using random sampling. Generate x and y randomly between 0 and 1. \n",
    "#  if x^2 + y^2 < 1 it's inside the quarter circle. x 4 to get pi. \n",
    "import ray\n",
    "from random import random\n",
    "\n",
    "# Let's start Ray\n",
    "ray.init()\n",
    "\n",
    "SAMPLES = 1000000; \n",
    "# By adding the `@ray.remote` decorator, a regular Python function\n",
    "# becomes a Ray remote function.\n",
    "@ray.remote\n",
    "def pi4_sample():\n",
    "    in_count = 0\n",
    "    for _ in range(SAMPLES):\n",
    "        x, y = random(), random()\n",
    "        if x*x + y*y <= 1:\n",
    "            in_count += 1\n",
    "    return in_count\n",
    "\n",
    "# To invoke this remote function, use the `remote` method.\n",
    "# This will immediately return an object ref (a future) and then create\n",
    "# a task that will be executed on a worker process. Get retreives the result. \n",
    "future = pi4_sample.remote()\n",
    "pi = ray.get(future) * 4.0 / SAMPLES\n",
    "print(f'{pi} is an approximation of pi') \n",
    "\n",
    "# Now let's do this 100,000 times. \n",
    "# With regular python this would take 11 hours\n",
    "# Ray on a modern laptop, roughly 2 hours\n",
    "# On a 10-node Ray cluster, roughly 10 minutes \n",
    "BATCHES = 100000\n",
    "results = [] \n",
    "for _ in range(BATCHES):\n",
    "    results.append(pi4_sample.remote())\n",
    "output = ray.get(results)\n",
    "pi = sum(output) * 4.0 / BATCHES / SAMPLES\n",
    "print(f'{pi} is a way better approximation of pi') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ray AIR\n",
    "What it is, and what is it in relation to the other libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Data\n",
    "Ray Datasets are the standard way to load and exchange data in Ray libraries and applications. They provide basic distributed data transformations such as map, filter, and repartition, and are compatible with a variety of file formats, data sources, and distributed frameworks.\n",
    "### Why Ray Data?\n",
    "- Built for Scale: Run basic data operations such as map, filter, repartition, and shuffle on petabyte-scale data in native Python code\n",
    "- Distributed Arrow: With a distributed Arrow backend, it easily works with a variety of file formats, data sources, and distributed frameworks.\n",
    "- Ray Ecosystem: Load your data once and enjoy a pluggable experience Ray once your data is in your Ray cluster with Datasets, leveraging Ray is a breeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset of Python objects.\n",
    "ds = ray.data.range(10000)\n",
    "# -> Dataset(num_blocks=200, num_rows=10000, schema=<class 'int'>)\n",
    "\n",
    "ds.take(5)\n",
    "# -> [0, 1, 2, 3, 4]\n",
    "\n",
    "ds.count()\n",
    "# -> 10000\n",
    "\n",
    "# Create a Dataset of Arrow records.\n",
    "ds = ray.data.from_items([{\"col1\": i, \"col2\": str(i)} for i in range(10000)])\n",
    "# -> Dataset(num_blocks=200, num_rows=10000, schema={col1: int64, col2: string})\n",
    "\n",
    "ds.show(5)\n",
    "# -> {'col1': 0, 'col2': '0'}\n",
    "# -> {'col1': 1, 'col2': '1'}\n",
    "# -> {'col1': 2, 'col2': '2'}\n",
    "# -> {'col1': 3, 'col2': '3'}\n",
    "# -> {'col1': 4, 'col2': '4'}\n",
    "\n",
    "ds.schema()\n",
    "# -> col1: int64\n",
    "# -> col2: string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Train\n",
    "Ray Train is a lightweight library for distributed deep learning that allows you to easily supercharge your distributed PyTorch and TensorFlow training on Ray.\n",
    "### Why Ray Train?\n",
    "- Native Multi-GPU Support: Easily scale from single threaded to multi-GPU training in under 10 lines of code.\n",
    "- Intuitive API: With a best-in-class API for gradient descent, migrate to production or scale to a large cluster without rewriting code.\n",
    "- Framework-agnostic: Seamlessly works with best-in-class deep learning frameworks including PyToch, Tensorflow, Horovod, and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train as train\n",
    "from ray.train import Trainer\n",
    "import torch\n",
    "\n",
    "def train_func():\n",
    "    # Setup model.\n",
    "    model = torch.nn.Linear(1, 1)\n",
    "    model = train.torch.prepare_model(model)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "    # Setup data.\n",
    "    input = torch.randn(1000, 1)\n",
    "    labels = input * 2\n",
    "    dataset = torch.utils.data.TensorDataset(input, labels)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)\n",
    "    dataloader = train.torch.prepare_data_loader(dataloader)\n",
    "\n",
    "    # Train.\n",
    "    for _ in range(5):\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model.state_dict()\n",
    "\n",
    "trainer = Trainer(backend=\"torch\", num_workers=4)\n",
    "trainer.start()\n",
    "results = trainer.run(train_func)\n",
    "trainer.shutdown()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray RLLib\n",
    "RLlib is the industry-standard reinforcement larning Python frameowrk built on Ray. Designed for quick interation and a fast path to production, it includes 25+ latest algorithms that are all implemented to run at scale and in multi-agent mode.\n",
    "### Why RLlib?\n",
    "- Vibrant Community: Reinforcement learning is hard. Easily find code examples and connect with other developers and experts.\n",
    "- Distributed-first: Iterate quickly without needing to rewrite again to go to production or scale to a large cluster\n",
    "- State-of-the-Art: Choose from the latest and greatest in reinforcement learning algorithms to find the one best suited for your problem. Enjoy multi-agent support in all.\n",
    "- Support External Simulators: Optimize your policies using an industry- or problem-specific external simulator. Connect simulations to RLlib via its PolicyServer/Client architecture.\n",
    "- Seriously fast: Experience really fast policy evaluation with lower overhead than most algorithms.\n",
    "- Tap into Ray ecosystem: Find the perfect set of hyperparameters using Ray Tune. Serve your trained model in a massively parallel way with Ray Serve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    " \n",
    "tune.run(PPOTrainer, config={\n",
    "   \"env\": \"CartPole-v0\",\n",
    "   \"framework\": \"torch\",\n",
    "   \"log_level\": \"INFO\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Tune\n",
    "Ray Tune is a Python library for fast hyperparameter tuning at scale. Easily distribute your trial runs to quickly find the best hyperparameters.\n",
    "### Why Ray Tune?\n",
    "- State of the Art Algorithms: Maximize model performance and minimize training costs by using the latest algorithms such as PBT, HyperBAND, ASHA, and more.\n",
    "- Library Agnostic: Ray Tune supports all the popular machine learning frameworks, including PyTorch, TensorFlow, XGBoost, LightGBM, and Keras--use your favorite!\n",
    "- Built-In Distributed Mode: WIth built-in multi-GPU and multi-node support, and seamless fault tolerance, easily parallelize your hyperparameter search jobs.\n",
    "- Power Up Existing Workflows: Have an existing workflow in another library like HyperOpt and Ax? Integrate Ray Tine to improve performance with minimal code changes.\n",
    "- 10x Your Productivity: Start using Ray Tune by changing just a couple lines of code. Enjoy simpler code, automatic checkpoints and integrations with tools like MLflow and TensorBoard.\n",
    "- Hooks into the Ray Ecosystem: Use Ray Tune on its own, or combine with other Ray libraries such as XGBoost-Ray, RLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    " \n",
    "def objective(step, alpha, beta):\n",
    "   return (0.1 + alpha * step / 100)**(-1) + beta * 0.1\n",
    " \n",
    "def training_function(config):\n",
    "   # Hyperparameters\n",
    "   alpha, beta = config[\"alpha\"], config[\"beta\"]\n",
    "   for step in range(10):\n",
    "       # Iterative training function - can be any arbitrary training procedure.\n",
    "       intermediate_score = objective(step, alpha, beta)\n",
    "       # Feed the score back back to Tune.\n",
    "       tune.report(mean_loss=intermediate_score)\n",
    " \n",
    "analysis = tune.run(\n",
    "   training_function,\n",
    "   config={\n",
    "       \"alpha\": tune.grid_search([0.001, 0.01, 0.1]),\n",
    "       \"beta\": tune.choice([1, 2, 3])\n",
    "   })\n",
    " \n",
    "print(\"Best config: \", analysis.get_best_config(\n",
    "   metric=\"mean_loss\", mode=\"min\"))\n",
    " \n",
    "# Get a dataframe for analyzing trial results.\n",
    "df = analysis.results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Serve\n",
    "Ray Serve lets you serve machine learning models in real-time or batch using a simple Python API. Serve individual models or create composite model pipelines, where you can independently deploy, update, and scale individual components.\n",
    "### Why Ray Serve?\n",
    "- Pythonic API: Configure your model serving declartively in pure Python without needing YAML or JSON configs.\n",
    "- Low Latency, High Throughput: Horizontally scale across hundreds of processes or machines, while keeping the overhead in single-digit milliseconds.\n",
    "- Multi-model composition: Easily compose multiple models, mix model serving with business logic, and independently scale components, without complex microservices.\n",
    "- Framework-agnostic: Use a single tool to serve all types of models -- from PyTorch and Tensorflow to scikit-Learn models -- and business logic.\n",
    "- Fast API Integration: Scale an existing FastAPI server easily or define an HTTP interface for your model using its simple, elegant API.\n",
    "- Native GPU support: Using GPUs is as simple as adding one line of Python code. Maximize hardware utilization by sharing CPUs or GPUs between different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from ray import serve\n",
    "\n",
    "@serve.deployment(route_prefix=\"/iris\")\n",
    "class BoostingModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.label_list = iris_dataset[\"target_names\"].tolist()\n",
    "\n",
    "    async def __call__(self, request):\n",
    "        payload = await request.json()\n",
    "        print(f\"Received flask request with data {payload}\")\n",
    "\n",
    "        prediction = self.model.predict([payload[\"vector\"]])[0]\n",
    "        human_name = self.label_list[prediction]\n",
    "        return {\"result\": human_name}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Train model.\n",
    "    iris_dataset = load_iris()\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(iris_dataset[\"data\"], iris_dataset[\"target\"])\n",
    "\n",
    "    # Deploy model\n",
    "    serve.run(BoostingModel.bind(model))\n",
    "\n",
    "    # Query model\n",
    "    sample_request_input = {\"vector\": [1.2, 1.0, 1.1, 0.9]}\n",
    "    response = requests.get(\"http://localhost:8000/iris\", json=sample_request_input)\n",
    "    print(response.text)\n",
    "    \n",
    "    # prints\n",
    "    # Result:\n",
    "    # {\"result\": \"versicolor\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Clusters\n",
    "Unclear when to mention this elegantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ray Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed XGBoost / LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrations\n",
    "Ray integrates with many popular Python and machine learning libraries and frameworks, letting you scale your existing workloads with minimal code changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### Key Concepts\n",
    "#### Key API Elements in This Section\n",
    "#### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "567405a8058597909526349386224fe35dd047505a91307e44ed44be00113429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
